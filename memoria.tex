\documentclass[a4paper, 12pt, oneside]{book}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel} 
\usepackage{url}
\usepackage{graphicx}
\usepackage{float} 
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind}
\usepackage{latexsym}

\newcommand{\subsubsubsection}[1]{\paragraph{#1}\mbox{}\\}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\usepackage{listings}
\usepackage{color}

\definecolor{blue-violet}{rgb}{0.54, 0.17, 0.89}
\definecolor{midnight}{RGB}{0, 103, 149}
\definecolor{lightgray}{rgb}{.6,.6,.6}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

%\renewcommand{\footnotesize}{\scriptsize}

\lstdefinelanguage{Bash}{
	sensitive=false
}

\lstset
{
	language = Bash,
	literate = {\$\#}{{{\$\#}}}2 {\$\# }{{{\$\# }}}2,
	columns  = fullflexible
}

\lstdefinelanguage{JavaScript}{
	keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
	keywordstyle=\color{blue-violet}\bfseries,
	ndkeywords={class, export, boolean, throw, implements, import, this},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{lightgray}\ttfamily,
	stringstyle=\color{midnight}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

\lstset{
	language=JavaScript,
	backgroundcolor=\color{white},
	extendedchars=true,
	basicstyle=\footnotesize\ttfamily,
	showstringspaces=false,
	showspaces=false,
	tabsize=4,
	breaklines=true,
	showtabs=false,
	captionpos=b
}

\title{Comparativa de tecnologías de servidor para servicios basados en websocket}
\author{Michel Maes Bermejo}

\renewcommand{\baselinestretch}{1.5}

\begin{document}

\renewcommand{\refname}{Bibliografía} 
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA
\cleardoublepage
\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
\includegraphics[scale=0.6]{img/logos/urjc-logo.jpg} &
\end{tabular}

\vspace{1cm}

\Large
GRADO INGENIERÍA DEL SOFTWARE

\vspace{0.4cm}

\large
Curso Académico 2017/2018

\vspace{0.8cm}

Trabajo Fin de Grado

\vspace{2cm}

\LARGE
Comparativa de tecnologías de sistemas distribuidos para implementación de un servicio de salas de chat multiusuario 

\vspace{2cm}

\large
Autor : Michel Maes Bermejo \\
Tutor : Micael Gallego Carrillo

\end{center}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%
%%%% Resumen
%%%%%%%%%%%%%%%%%%%%

\chapter*{Resumen}
\pagenumbering{gobble}

\markboth{RESUMEN}{RESUMEN} % encabezado

En este proyecto abordaremos una comparativa entre diferentes tecnologías de sistemas distribuidos para implementación de chats multiusuario basadas en WebSockets. Para ello construiremos un total de 4 aplicaciones de chat utilizando diferentes tecnologías:

\begin{itemize}
	\item Akka
	\item Vert.x
	\item SpringBoot
\end{itemize}


Además de una aplicación para cada tecnología, completaremos el conjunto de las aplicaciones con dos variantes para la tecnología SpringBoot con el fin de encontrar su versión más óptima:

\begin{itemize}
	\item SpringBoot con RabbitMQ
	\item SpringBoot con Hazelcast
\end{itemize}

Para realizar esta comparativa de una forma justa, se desarrollará un cliente común a todas las aplicaciones que se encargue de tomar diferentes métricas, concretamente:

\begin{itemize}
	\item La latencia (o tiempo de respuesta)
	\item El uso de CPU
	\item El uso de memoria
\end{itemize}

Una vez la construcción de las aplicaciones haya finalizado, usaremos el cliente para obtener métricas de cada aplicación ante distintas cargas de trabajo.

Por último, analizaremos los resultados obtenidos para evaluar que tecnología resulta ser la más óptima para trabajar con WebSockets de forma distribuida.

%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%

%%%% Índice de contenidos
\tableofcontents 
%%%% Índice de figuras
\cleardoublepage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%       1.INTRODUCCIÓN Y MOTIVACIÓN           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducción y motivación}
\label{sec:intro} 
\pagenumbering{arabic} 

Hoy en día, un desarrollador de software tiene múltiples herramientas (entre lenguajes y librerías) para abordar cualquier proyecto que tenga entre manos.

Es una práctica común usar una tecnología concreta sobre la que sentimos predilección o las que creemos que pueden resolver mejor nuestro problema. En ocasiones, nos equivocamos en nuestra elección y descartamos opciones mucho más efectivas.

Este problema de desinformación puede abordarse mediante el estudio de las distintas tecnologías que proponen una solución al mismo, pero dado que el ámbito del desarrollo software es muy amplio, vamos a centrarnos en las tecnologías de sistemas distribuidos que permitan implementar chats multiusuario con conexión mediante WebSockets.

Estas tecnologías proporcionan una comunicación en tiempo real con clientes muy diversos (aplicaciones móviles, navegadores, otro servidores). Un ejemplo actual son los servicios de mensajería instantánea cómo WhatsApp o Telegram, cuyo crecimiento de usuarios se ha disparado en los últimos años. Hoy en día este tipo de aplicaciones tienen un impacto drástico en la vida diaria, siendo casi una herramienta imprescindible, por lo que prevenir una caída de servicio ante un alto número de clientes es fundamental.

La motivación de este proyecto surge de la necesidad de comprender mejor estas tecnologías y proporcionar argumentos sólidos que justifiquen el uso de una u otra, dependiendo de las necesidades de nuestro proyecto y de los recursos de los que dispongamos.

\clearpage

Para ello, tomaremos como punto de partida las tecnologías reactivas, que siguiendo el Manifiesto Reactivo\footnote{\url{http://www.reactivemanifesto.org/}} cuentan entre sus características:


\begin{itemize}  
	\item Tiempos de respuestas rápidos
	\item Tolerantes a fallos
	\item Adaptación a variaciones en la carga de trabajo
	\item Uso de mensajes asíncronos para la comunicación (no bloqueantes)
\end{itemize}

Para este proyecto, nos centraremos en Java, un lenguaje consolidado que cuenta con librerias y frameworks que nos ayudarán a abordar esta comparativa.

Este proyecto supone una continuación de otro trabajo anterior realizado por el mismo autor del proyecto que nos ocupa. En el anterior proyecto, se realizó una comparativa entre aplicaciones de Akka, Vert.x, SpringBoot y NodeJS, las cuales se compararon haciendo uso de una sola máquina (escalado vertical). La ampliación consistirá en abordar el problema de la escalabilidad horizontal (aplicaciones distribuidas en varias máquina) haciendo uso de las herramientas que nos proporciona cada tecnología o haciendo uso de herramientas externas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             2. Objetivos                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Objetivos}
\label{sec:objetivos} 

El objetivo principal de este proyecto será realizar una comparativa entre distintas tecnologías distribuidas que den solución a la comunicación en tiempo real mediante el uso de WebSockets. Dicha comparativa se realizará en base al rendimiento y el consumo de recursos de cada una de las tecnologías comparadas, ante diferentes niveles de carga y haciendo uso de un número variado de servidores.

Con este fin, se implementará un servidor de mensajería instantánea (que a partir de ahora denominaremos simplemente Chat) para cada tecnología y un cliente que se conectará a ese servidor simulando varios usuarios enviando mensajes que podrá medir el tiempo que tarda un mensaje desde que se envía hasta que se recibe.

Otro objetivo relevante del proyecto será su extensibilidad, de forma que cualquier desarrollador pueda implementar su aplicación de chat, sumarla a la comparativa y así contribuir al proyecto.

Este proyecto pretende ser una continuación y expansión del anteriormente mencionado, concretamente:

\begin{itemize}  
	\item Distribuir cada aplicación para que pueda ser lanzada en varias máquinas que formen un clúster.
	\item Actualizar las librerias a su última versión a fin de contar con las herramientas más recientes.
	\item Mejorar el cliente existente para que sea capaz de recoger métricas de una aplicación distribuida.
\end{itemize}

Las tecnologías que compararemos en este proyecto serán:

\begin{itemize}  
	\item Akka
	\item Vert.x
	\item SpringBoot + RabbitMQ
	\item SpringBoot + Hazelcast
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3. Tecnologías, Herramientas y Metodologías %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Tecnologías, Herramientas y Metodologías}
\label{sec:tecnologias} 

De la multitud de lenguajes de programación que existen válidos para afrontar el desarrollo de un servidor basado en WebSocket nuestra primera opción ha sido seleccionar Java, que dispone de múltiples librerías interesantes para abordar el problema además de ser uno de los lenguajes de programación más extendidos, populares y con una amplia comunidad, como demuestra el informe TIOBE (Ver figura~\ref{figura:tiobe}).


\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/tiobe.png}
	\caption{Índice TIOBE}
	\label{figura:tiobe}
\end{figure}

\section{Tecnologías}

\subsection{Websockets}
\label{subsec:websockets}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/logos/ws-logo.png}
	\caption{Logo WebSockets}
	\label{figura:ws}
\end{figure}

RFC 6455\footnote{\url{https://tools.ietf.org/html/rfc6455}} define WebSocket (Figura~\ref{figura:ws}) como un protocolo que proporciona un canal de comunicación bidireccional y full-dúplex sobre un único socket TCP. Aunque inicialmente estaba pensado para cualquier tipo de comunicaciones entre el navegador y el servidor web, puede usarse también para aplicaciones cliente/servidor.

Por otro lado, W3C se encarga de normalizar la API\footnote{\url{https://www.w3.org/TR/2011/WD-websockets-20110929}} de WebSocket. Define una interfaz para el navegador compuesta por 4 métodos que corresponden a manejadores o gestores (\textsl{handlers}) para cada evento. 

Podemos ver un ejemplo de estos manejadores en el código mostrado a continuación (Javascript en el navegador).

\begin{lstlisting}[language=JavaScript]
	var socket = new WebSocket("ws://example.com:9000/chat");
	// Send new text
	socket.send("Some text");
	socket.onmessage = function(event) {
		var data = JSON.parse(event.data);
		// Use data
	});
	socket.onopen  = function(e){ console.log("WS Opened")};
	socket.onclose = function(e){ console.log("WS Closed")};
	socket.onerror = function(e){ console.log(e)};
\end{lstlisting}


\subsection{Java}
\label{subsec:java}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.06]{img/logos/java-logo.png}
	\caption{Logo Java}
	\label{figura:java}
\end{figure}

Java (Figura~\ref{figura:java}) es un lenguaje de programación de propósito general, concurrente y orientado a objetos. Su sintaxis deriva en gran medida de C y C++. Uno de los principales atractivos de Java es su máquina virtual (JVM) que nos permite ejecutar nuestro código Java en cualquier dispositivo, independientemente de la arquitectura. Las tecnologías basadas en Java seleccionadas para la comparativa son explicadas a continuación.

\subsection{Akka}
\label{subsec:akka}

\begin{center}
	
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.2]{img/logos/akka-logo.png}
	\caption{Logo Akka}
	\label{figura:akka}
\end{figure}

Akka\footnote{\url{http://akka.io/}} (Figura~\ref{figura:akka}) es un toolkit para crear aplicaciones concurrentes y distribuidas. También se ejecuta sobre la JVM. Se puede utilizar con Java y Scala, lenguaje con el que está implementado y del que su implementación de los actores forma parte de la librería estándar desde la versión 2.10. Otras de sus características son:


\begin{itemize}  
	\item \textbf{Tolerancia a fallos}: Akka adopta el modelo de \textit{let it crash} que ha resultado un gran éxito en la industria de la telecomunicación.
	\item \textbf{Transparencia de localización}: todo en Akka está diseñado para trabajar en un entorno distribuido: todas las comunicaciones son mediante paso de mensajes y todo es asíncrono
	\item \textbf{Persistencia}: Los mensajes recibidos por el actor pueden conservarse y ser reproducidos al iniciar o reiniciar el actor, por lo que se puede conservar el estado de los actores después de un fallo o al migrarlos a otro nodo.
\end{itemize}

La versión utilizada de Akka durante este proyecto es la 2.5.

La aplicación de Akka hace uso de Play Framework\footnote{\url{https://www.playframework.com/}} un framework web open source, que da soporte web a la aplicación y proporciona la comunicación mediante WebSockets.

Los conceptos básicos que debemos comprender de Akka son:

\begin{itemize}  
	\item \textbf{Actores}: Los actores son objetos que poseen un estado y un comportamiento. Se comunican entre ellos exclusivamente enviando mensajes que se encolan en el mailbox del actor de destino. Los actores se organizan jerárquicamente. Un actor encargado de realizar una tarea, puede dividir esa tarea en otras sub-tareas y enviárselas a unos actores hijos a los que supervisará.
	\item \textbf{Actor System}: Es el encargado de ejecutar, crear y borrar actores además de otros fines como la configuración o el logging. Varios actor systems con diferentes configuraciones puede coexistir en la misma JVM sin problemas, aunque al ser una estructura pesada que puede manejar de 1..N threads, se recomienda crear una por aplicación.
	\item \textbf{Actor Reference}: Es un objeto que representa al actor en el exterior. Estos objetos pueden enviarse sin ninguna restricción y permiten enviar mensajes al actor con total transparencia, sin necesidad de actualizar las referencias a pesar de enviarse a otros hosts. Además evitan que desde el exterior pueda conocerse el estado del actor a no ser que este lo publique.
	\item \textbf{Actor Path}: Como los actores son creados en una estricta estructura jerárquica, existe una única secuencia de nombres de actores dados siguiendo recursivamente los links entre actores padres e hijos hasta el actorSystem. Esta secuencia similar a las rutas de un sistema de ficheros, por ello es conocida como actor Path.
\end{itemize}

La diferencia entre un ActorPath y una ActorReference es que el segundo tiene el mismo ciclo de vida que el actor. Si el actor se destruye su ActorReference también, sin embargo un ActorPath puede existir perfectamente a pesar de que no exista el actor.

\subsection{Hazelcast}
\label{subsec:hazelcast}

\begin{center}
	
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.3]{img/logos/hazelcast-logo.png}
	\caption{Logo Hazelcast}
	\label{figura:hazelcast}
\end{figure}

Hazelcast \footnote{\url{https://hazelcast.com/}} (Figura~\ref{figura:hazelcast}) es un DataGrid de Java, una herramienta escalable para la distribución de datos.

Entre algunos de sus usos principales, se encuentran:

\begin{itemize}
	\item Cacheo de datos de forma distribuida.
	\item Ejecución paralela.
	\item Mensajería distribuida.
	\item Escalado dinámico.
	\item Transacciones sobre los datos.
	\item Querys sobre los datos.
\end{itemize}

Para este proyecto nos interesa la mensajeria distribuida, que funciona mediante un patrón publicar-subscribir sencillo de distribuir entre diferentes nodos.

\pagebreak

\subsection{Vert.x}
\label{subsec:vertx}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.1]{img/logos/vertx-logo.png}
	\caption{Logo Vert.x}
	\label{figura:vertx}
\end{figure}

Vert.x\footnote{\url{http://vertx.io/}} (Figura~\ref{figura:vertx}) es otro toolkit de Java que permite construir aplicaciones reactivas. Se autodenomina dirigido por eventos y no bloqueante, está inspirado en Node.js. La versión utilizada en el proyecto es la 3.5.

Los conceptos básicos que debemos comprender de Vert.x son:

\begin{itemize}  
	\item \textbf{Verticle}\footnote{\url{http://vertx.io/docs/vertx-core/java/#verticles}}: modelo de concurrencia que propone Vertx. Un Verticle es una clase que se comporta como un actor\footnote{\url{https://en.wikipedia.org/wiki/Actor_model}}, cuyo comportamiento está orientado a enviar/recibir mensajes. Para facilitar el desarrollo, Vertx asegura que el código de un verticle nunca va a ser ejecutado por más de un thread a la vez.
	\item \textbf{EventBus}: es uno de sus principales recursos que le da su carácter reactivo. Consiste en un bus transversal a la aplicación que permite la comunicación entre los verticles de distintas formas\footnote{\url{http://vertx.io/docs/apidocs/io/vertx/core/eventbus/EventBus.html}}:
	\item \textbf{Publicar-Subscribir}: Diversos verticles se subscriben a un determinado topic proporcionando un handler que opere con la respuesta. Tras esto, basta con publicar un mensaje bajo ese topic para que todos los componentes subscritos lo reciban.
	\item \textbf{Punto a punto}: Al igual que el anterior, envía un mensaje bajo un topic, pero en este caso, solo a uno de los subscriptores, elegido mediante un algoritmo de round-robin no estricto.
	\item \textbf{Petición-Respuesta}: Similar al anterior, con la única diferencia que se proporciona un handler para una posible respuesta.
	\item \textbf{Context}\footnote{\url{https://github.com/vietj/vertx-materials/blob/master/src/main/asciidoc/Demystifying_the_event_loop.adoc}}: se encarga de controlar un ámbito concreto de la aplicación, además del orden en el que los callbacks/handlers son ejecutados. Vertx dispone de 3 tipos diferentes de contexts:
	\begin{itemize}
		\item Event-loop: ejecuta los handlers de forma que un mismo handler es ejecutado únicamente en un Thread y este no debe ser bloqueante de ninguna manera (uso de herramientas de bloqueo condicional, llamadas a bases de datos, ejecuciones del sistema largas, etc ...). Este modelo no es dependiente la sincronización y dota a Vertx, junto al EventBus de su reactividad, además de su carácter no bloqueante. Es el context usado por defecto.
		\item Worker: contexto ligado a los verticles, que siguen asegurando que se ejecutan en un solo Thread, pero permiten su bloqueo.
		\item Multi-Thread Worker: Permite la ejecución de un verticle en diferentes threads, de forma que pueda realizar las tareas de forma concurrente, delegando en el desarrollador la responsabilidad de asegurar la concurrencia y sincronización.
	\end{itemize}
\end{itemize}

Además de los recursos mencionados, cuenta con una extensa API que abarca desde múltiples herramientas de testing hasta servidores y clientes de TCP/SSL, HTTP/HTTPS y WebSockets, cobrando estos últimos especial importancia de cara al desarrollo de la aplicación.

Vert.x utiliza Hazelcast por defecto para distribuir su bus de eventos y otras funcionalidades distribuidas, aunque puede usarse también con Ignite\footnote{\url{https://ignite.apache.org/}}, Infinispan\footnote{\url{http://infinispan.org/}} o Zookeeper\footnote{\url{http://zookeeper.apache.org/}}. Para este proyecto usaremos la configuración por defecto con Hazelcast.

\pagebreak

\subsection{SpringBoot}
\label{subsec:springboot}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{img/logos/springboot-logo.png}
	\caption{Logo SpringBoot}
	\label{figura:springboot}
\end{figure}

Spring Boot\footnote{\url{http://projects.spring.io/spring-boot/}}  (Figura~\ref{figura:springboot}) comprende un módulo de Spring\footnote{\url{https://spring.io/}} (un framework para el desarrollo de aplicaciones web) que provee de todo lo necesario para crear una aplicación con un mínimo de configuración lista para lanzar. Spring Boot proporciona:

\begin{itemize}  
	\item Una experiencia de iniciación muy rápida

	\item Prototipos extensibles para la mayoría de problemas que podamos tener

	\item Características no funcionales comunes a la mayoría de proyectos (servidores integrados, seguridad, métricas, comprobaciones de estado, configuración externalizada).
\end{itemize}

Además, cuenta con el Sistema de Inversión de Control de Spring\footnote{\url{https://en.wikipedia.org/wiki/Inversion_of_control}}\footnote{\url{https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html}}, que permite la configuración de los componentes de la aplicación, mientras que la administración del ciclo de vida de los objetos se lleva a cabo a través de la inyección de dependencias\footnote{\url{https://en.wikipedia.org/wiki/Dependency_injection}} (que a su vez es una forma de inversión de control).

La versión utilizada de Spring para este proyecto es la 2.0.3

\subsection{RabbitMQ}
\label{subsec:rabbitmq}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.2]{img/logos/rabbitmq-logo.png}
	\caption{Logo RabbitMQ}
	\label{figura:rabbit}
\end{figure}

RabbitMQ\footnote{\url{https://www.rabbitmq.com/}} (Figura~\ref{figura:rabbit}) es un software de mensajería de código abierto implementado en Erlang\footnote{\url{https://www.erlang.org/}} que implementa el protocolo de cola de mensajes avanzados (AMQP\footnote{\url{https://es.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol}}), además de otros protocolos que ha ido añadiendo  cómo STOMP\footnote{\url{https://en.wikipedia.org/wiki/Streaming_Text_Oriented_Messaging_Protocol}} y MQTT\footnote{\url{https://en.wikipedia.org/wiki/MQTT}}. Para este proyecto usaremos la versión 3.5.7.

Entre las caracteristicas mas relevantes que encontramos en esta tecnología, que comparte con otras tecnologías de colas de mensajes, están las siguientes:

\begin{itemize}  
	\item \textbf{Garantía de entrega y orden}: los mensajes se consumen en el mismo orden que se llegaron a la cola y son consumidos una única vez.
	\item \textbf{Redundancia}: Las colas mantienen los mensajes hasta que son procesados por completo.
	\item \textbf{Desacoplamiento}: al actuar cómo un middleware, siendo una capa intermedia de comunicación entre procesos, aportan la flexibilidad en la definición de arquitectura de cada uno de ellos de manera separada, siempre que se mantenga una interfaz común.
	\item \textbf{Escalabilidad}: con más unidades de procesamiento, las colas balancean su respectiva carga.
\end{itemize}

Al contrario que Vert.x o Akka, RabbitMQ es un servicio externo (pudiendo estar o no en la misma máquina dónde se ejecute nuestra aplicación). Para hacer uso de este middleware será necesario un cliente que interactúe con él.

Los conceptos principales para entender RabbitMQ son:

\begin{itemize}  
	\item \textbf{Exchange}: punto de entrada de los mensajes. Pueden ser:
	\begin{itemize}
	 \item \textit{Direct} entrega un mensaje a una sola cola, \item \textit{Fanout} entrega copias del mensaje a todas las colas
	 \item \textit{Topic}: entrega copias del mensaje sólo a algunas colas.
	\end{itemize}
	\item \textbf{Queue}: punto de lectura de los mensajes. Pueden ser durable o persistentes (si almacenan los mensajes para sobrevivir a un reinicio de RabbitMQ). También pueden ser exclusivas, si sólo un consumidor puede estar conectado a la vez.
	\item \textbf{Bindings}: definen cómo llegar de un \textit{Exchange} a las \textit{Queue} asociadas.
	
	\item \textbf{Routing key o topic}: filtro asociado a un Binging que permite seleccionar sólo algunos mensajes para dicho binding.
	
	\item \textbf{Productor}: programa que escribe en un Exchange
	\item \textbf{Consumidor}: programa que escucha en una Queue
\end{itemize}

\subsection{HA PROXY}
\label{subsec:haproxy}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/logos/haproxy-logo.png}
	\caption{Logo HAProxy}
	\label{figura:ha}
\end{figure}

HAProxy (Figura~\ref{figura:ha}) es una solución gratuita, muy rápida y confiable que ofrece alta disponibilidad, balanceo de carga y proxying para aplicaciones TCP y HTTP. Es especialmente adecuado para sitios web de mucho tráfico. Está escrito en C y tiene la reputación de ser rápido y eficiente en términos de uso del procesador y consumo de memoria. Con el paso de los años, se ha convertido en el estándar de facto del balanceador de carga opensource, ahora se incluye con la mayoría de las distribuciones de Linux, y a menudo se implementa de manera predeterminada en las plataformas en la nube.

\pagebreak

\subsection{Angular}
\label{subsec:angular}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.1]{img/logos/angular-logo.png}
	\caption{Logo Angular}
	\label{figura:angular}
\end{figure}

Angular\footnote{\url{https://angular.io/}} (Figura~\ref{figura:angular})
es un framework de JavaScript (aunque comúnmente se utiliza con Typescript\footnote{\url{https://www.typescriptlang.org/}}, un superconjunto de Javascript) de código abierto desarrollado por Google. Nos permite desarrollar SPAs (Single Page Applications), que siguiendo el MVC (modelo-vista-controlador), facilitan la presentación y manipulación de los datos en el lado cliente (frontend), reduciendo la carga lógica del lado servidor (backend). La versión utilizada para este proyecto es la 5.2.

Entre sus características, destacamos:

\begin{itemize}  
	\item La extensión del html mediante etiquetas y sintaxis propia.
	\item Inyección de dependencias
	\item Una numerosa comunidad y una extensa documentación
\end{itemize}

Utilizaremos Angular para ofrecer un cliente web en el que mostrar los resultados del experimento.

\section{Herramientas}

\subsection{Control de versiones: Git}
\label{subsec:git}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.15]{img/logos/git-logo.png}
	\caption{Logo Git}
	\label{figura:git}
\end{figure}


Git\footnote{\url{https://git-scm.com/}} (Figura~\ref{figura:git}) es un software de control de versiones diseñado por Linus Torvalds, pensando en la eficiencia y la confiabilidad del mantenimiento de versiones de aplicaciones cuando éstas tienen un gran número de archivos de código fuente.

Para el desarrollo de este proyecto hemos usado GitHub\footnote{\url{https://github.com}}, una plataforma de desarrollo colaborativa para alojar proyectos Git.

A pesar de su integración con diversos entornos de desarrollo, se ha optado por su versión de línea de comandos.

\subsection{Gestores de dependencias}
\label{subsec:getsores_dependencias}

Debido a la pluralidad de tecnologías, hemos utilizado distintos gestores de dependencias:


\subsubsection{Maven}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/logos/maven-logo.png}
	\caption{Logo Maven}
	\label{figura:maven}
\end{figure}


Maven\footnote{\url{https://maven.apache.org/}} (Figura~\ref{figura:maven}) es una herramienta de software para la gestión y construcción de proyectos Java creada por Jason van Zyl. Hace uso de un POM (Project Object Model), un archivo XML que describe las dependencias y permite añadir opciones de ejecución, test y desplegamiento de la aplicación.

Se ha utilizado para configurar los proyectos en Vert.x y Spring Boot.

\subsubsection{SBT}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.4]{img/logos/sbt-logo.png}
	\caption{Logo SBT}
	\label{figura:sbt}
\end{figure}


SBT\footnote{\url{http://www.scala-sbt.org/}} (Figura~\ref{figura:sbt}) es una herramienta de software para construcción de proyectos en Scala y estándar para contruir aplicaciones en Play Framework, similar a Maven o Ant (propios de Java). Entre sus características, permite el uso conjunto de Java y Scala en el mismo proyecto. Su archivo de configuración es un.stb, que dispone dispone de sintaxis propia.

Se ha utilizado para configurar el proyecto de Akka.

\subsection{AWS}
\label{subsec:aws}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.05]{img/logos/aws-logo.png}
	\caption{Logo AWS}
	\label{figura:aws}
\end{figure}


Amazon Web Services\footnote{\url{https://aws.amazon.com}} (AWS) (Figura~\ref{figura:aws}) es una plataforma de servicios de nube que ofrece potencia de cómputo, almacenamiento de bases de datos, entrega de contenido y otras funcionalidades.

Concretamente se ha utilizado su servicio EC2\footnote{\url{https://aws.amazon.com/es/ec2}}, que nos permite lanzar instancias que contengan nuetras aplicaciones en la nube. Para este proyecto se ha hecho uso de la capa gratuita.

Para hacer uso de esta plataforma, se ha utilizado su interfaz mediante línea de comandos\footnote{\url{https://aws.amazon.com/es/cli}}.


\subsection{Entornos de desarrollo}
\label{subsec:entornos}

\subsubsection{IntelliJ}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/logos/intellij-logo.png}
	\caption{Logo IntelliJ}
	\label{figura:intellij}
\end{figure}


IntelliJ\footnote{\url{https://www.jetbrains.com/idea/}} (Figura~\ref{figura:intellij}) es un IDE para Java desarollado por JetBrains ideado para mejorar la productividad del programador. Entre sus características incluye:

\begin{itemize}  
	\item Soporte para los lenguajes basados en la JVM (Java, Scala, Groovy y Kotlin)
	\item Soporte para diferentes frameworks basados en estos lenguajes (Spring, Play, JavaEE\dots)
	\item Control de versiones
	\item Asistencia al escribir código y autocompletar
	\item Soporte para programar en web (HTML, CSS y Javascript)
\end{itemize}

Se ha utilizado este IDE para desarrollar los distintos servidores de chat, ya que todos ellos están basados en Java.

\subsubsection{Atom}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.4]{img/logos/atom-logo.jpg}
	\caption{Logo Atom}
	\label{figura:atom}
\end{figure}


Atom\footnote{\url{https://atom.io/}} (Figura~\ref{figura:atom}) es un editor de texto sencillo, ligero y extensible creado por Github. Cuenta con una gran librería de paquetes aportados por la comunidad para facilitar el desarrollo software. Por defecto, no cuenta con ningún tipo de compilador o intérprete.

Se ha utilizado de forma conjunta con IntelliJ para desarrollar la aplicación de pruebas, ya que cuenta con paquetes que nos ayudan a desarrollar aplicaciones en Angular y soporte para Typescript.


\section{Metodologías}

El modelo de desarrollo de este proyecto se ha llevado a cabo a través de TDD\footnote{\url{https://es.wikipedia.org/wiki/Desarrollo_guiado_por_pruebas}}(Test-driven Development, o en español, \textbf{desarrollo guiado por pruebas}, ver figura~\ref{figura:tdd}), una práctica de Ingeniería del Software cuya principal idea es hacer que los requistos sean traducidos a pruebas. En este proyecto, los requisitos (que se detallarán mas adelante), son probados en conjunto en lugar de individualmente.

Las razones que han llevado a utilizar un ciclo de desarrollo conducido por pruebas son:

\begin{itemize}  
	\item La naturaleza intrínseca del proyecto, distintas aplicaciones cuyo funcionamiento debe ser el mismo y por tanto comparten requisitos.
	\item La herencia de un proyecto, que proporcionaba dichas pruebas de integración necesarias para validar cualquier aplicación.
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=1.2]{img/tdd.png}
	\caption{Ciclo del TDD}
	\label{figura:tdd}
\end{figure}

Junto a un desarrollo dirigido por pruebas, usamos una metodología \textbf{iterativa-incremental} dónde, una vez que hacemos pasar las pruebas, procedemos a refactorizar la aplicación para mejorar su rendimiento (mejores métricas de latencia y consumo de recursos) y su mantenibilidad (fácilidad para ampliar o cambiar el código de la aplicación), pasando las pruebas de nuevo con cada iteración.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 		 4. Descripción informática           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Descripción informática}
\label{sec:descripcion}

En este apartado se abordará la construcción del proyecto. Todo el proyecto (que incluye tanto las aplicaciones de chat como el cliente de pruebas, pueden encontrarse como repositorios en la organización de GitHub: \textit{TFG-DistributedWebChat}\footnote{\url{https://github.com/TFG-DistributedWebChat}}.

El proyecto realizado consta de 3 aplicaciones de chat y un cliente de pruebas. Las aplicaciones construidas y que entran a formar parte de la comparativa son:

\begin{itemize}  
	\item Akka
	\item Vert.x
	\item SpringBoot + RabbitMQ
	\item SpringBoot + Hazelcast
\end{itemize}


La comparativa tomará en cuenta la escalabilidad horizontal, por lo que todas las aplicaciones se desarrollaran para funcionar de forma distribuida en 2 o más máquinas

\section{Requisitos}

Como se ha mencionado anteriormente, este proyecto es la continuación de uno anterior, del que se ha heredado un cliente de chat que funciona como prueba de integración. Los requisitos, por lo tanto, quedan condicionados al funcionamiento de dicho cliente. Cada aplicación se construirá siguiendo los mismos requisitos.

Distinguiremos entre requisitos funcionales y no funcionales:

\subsection{Requisitos funcionales}

Los requisitos funcionales fueron detallados como documentación y publicados como una página en una wiki de GitHub para que cualquier desarrollador pudiera incluir su propia aplicación. Su versión en inglés puede encontrarse en la documentación del proyecto en GitHub \footnote{\url{https://github.com/TFG-DistributedWebChat/DistributedWebChatClient/wiki/Requeriments}}, mientras que su versión en español se detalla a continuación.

\textbf{Requisitos básicos}

La aplicación en cuestión debe poder soportar un chat en el que varios usuarios puedan comunicarse entre si.

Requiere lanzar la aplicación como un servidor que escuche de un puerto concreto y ofrecer una conexión WebSocket sobre la dirección \textit{/chat}.

\textbf{Primera conexión}

El cliente, al establecer la conexión enviará sus datos en un string, que podrá formatearse a JSON y tiene la siguiente estructura:

\begin{lstlisting}[language=JavaScript]
	{
		"name": "MyName",
		"chat": "MyRoom"
	}
\end{lstlisting}

La aplicación debe almacenar estos datos junto a la conexión WebSocket, de forma que queden registrados.


\textbf{Recepción y reenvío de mensajes} 

Una vez se ha establecido la conexión y se ha mandado el mensaje de inicialización, el cliente enviará mensajes a la aplicación, de nuevo como un String, que se podrá formatear a un JSON con la siguiente estructura:

\begin{lstlisting}[language=JavaScript]
	{
		"name": "MyName",
		"chat": "MyRoom",
		"message":"MyMessage"
	}
\end{lstlisting}

Este mensaje debe ser reenviado por la aplicación a todos los usuarios cuya sala de chat sea la misma que la del mensaje\footnote{No debe confundirse un mensaje de chat con un mensaje de conexión, la forma de diferenciarlos es por la existencia o no de la clave \textit{message} en el JSON.}.

\textbf{Desconexión}

La aplicación debe gestionar la desconexión de usuarios, de forma que cuando un usuario se desconecta, este debe eliminarse de la aplicación para que no se le reenvíen mensajes.

\textbf{Opcionales}

Aunque las pruebas que se realizan no lo requieren, para añadirle dificultad, la aplicación puede impedir que dos usuarios con el mismo nombre puedan conectarse (independientemente del chat al que pertenezcan). En caso de que ya exista el usuario debería enviar un mensaje de vuelta al cliente tal y cómo se muestra a continuación:

\begin{lstlisting}[language=JavaScript]
	{
		"type": "system",
		"message": "A user with that name already exists"
	}
\end{lstlisting}

Además, y de cara a probar rápidamente el correcto funcionamiento más básico de la aplicación, puede ofrecerse un cliente http que permita realizar la conexión desde el navegador.

\subsection{Requisitos no funcionales}

Dado el carácter comparativo que posee el proyecto, nos centraremos en los requisitos de calidad de ejecución, a fin de optimizar lo máximo posible cada aplicación. Los requisitos no funcionales más relevantes en el proyecto serán:

\begin{itemize}  
	\item \textbf{Latencia}: Las aplicaciones deben ofrecer un tiempo de respuesta lo más bajo posible dentro de las características de la tecnología en la que se base.
	\item \textbf{Consumo de recursos}: Las aplicaciones deben hacer un uso responsable de los recursos del sistema (como son la memoria o el uso del procesador).
	\item \textbf{Escalabilidad}: en nuestro caso, será escalabilidad vertical, que buscará que nuestras aplicaciones no vean degradada su calidad (en este caso una baja latencia y consumo de recursos) ante grandes cargas de trabajo.
	\item \textbf{Concurrencia}: Las aplicaciones tienen que estar libres de interbloqueos y esperas innecesarias. Dada la naturaleza de la mayoría de tecnologías (reactivas y no bloqueantes), este requisito es fácilmente satisfacible.
\end{itemize}

\section{Diseño e Implementación}

El proyecto seguirá la arquitectura planteada en figura~\ref{figura:desing}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{img/diagrams/design.png}
	\caption{Arquitectura del proyecto}
	\label{figura:desing}
\end{figure}


Al iniciar el experimento (una vez desplegados los nodos de la aplicación en clúster), el cliente abrirá varias conexiones WebSocket con el servidor, simulando varios usuarios, enviando mensajes a través de ellas y recogiendo diversas métricas. Estas métricas serán enviadas a través de WebSocket a una aplicación web en el navegador, que mostrará dichas métricas mediante el uso de gráficas en tiempo real. Las métricas podrán ser descargadas desde el navegador en formato JSON.

Los nodos del diagrama deberá poder ser cualquiera de las aplicaciones participantes en la comparativa (cuentan con los mismos requisitos), de forma que el cliente pueda interactuar con ellos independientemente de la implementación que posean.

A continuación, se expondrá el diseño e implementación de cada aplicación construida, así como un acceso a su código fuente. La infraestructura necesaria para desplegar cualquier aplicación esta definida en el apéndice A de este documento.

\subsection{Akka}

El código de esta aplicación se puede encontrar en un repositorio en GitHub de la organización antes mencionada bajo el nombre de \textit{Akka-DistributedWebChat}\footnote{\url{https://github.com/TFG-DistributedWebChat/Akka-DistributedWebChat}}

\textbf{Diseño y arquitectura}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/diagrams/Akka-Diagram.png}
	\caption{Arquitectura de la aplicación de Akka}
	\label{figura:akka_ds}
\end{figure}


La aplicación de Akka, tal y cómo vemos en la figura~\ref{figura:akka_ds} hace uso del patron Publicar-Subscribir\footnote{\url{https://en.wikipedia.org/wiki/Publish-subscribe_pattern}}, permitiendo que el actor \textit{User} sea capaz de interactura con otros de su mismo tipo incluso aunque se encuentren en otra máquina distinta bajo un topic que será en nombre de su sala de chat. Este actor es capaz de:
\begin{itemize}  
	\item Publicar nuevos mensajes que lleguen del cliente bajo un topic al resto de usuarios de la sala.
	\item Recibir (mediante subscripción) mensajes de un topic y enviarselos al cliente.
\end{itemize}


\textbf{Funcionamiento}

\begin{itemize}  
	\item \textbf{Conexión}: Cuando un cliente abre la conexión, Play ejecuta el siguiente método:
	
	\begin{lstlisting}[language=Java]
	// /app/controllers/Application.java
	public WebSocket<String> socket() {
		return WebSocket.withActor(User::props);
	}
	\end{lstlisting}
	
	La llamada al método estático props devuelve un nuevo actor User al que asigna la conexión WebSocket establecida que representa al cliente, tal y como se muestra en el código a continuación:
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	public static Props props(ActorRef out) {
		return Props.create(User.class, out);
	}
	\end{lstlisting}
	
	Al crearse el actor, también se le asigna una referencia a un mediador, que gestionará nuestras peticiones de publicar y subscribirnos a mensajes.
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	this.mediator = DistributedPubSub
		.get(getContext().system())
		.mediator();
	\end{lstlisting}
	
	Una vez creado el actor, es capaz de recibir mensajes y estos serán tratados mediante las reglas que hayamos definido en su método \textit{createReceive()}. Este método diferenciará entre mensajes que lleguen de la clase \textit{String} (llegan del cliente) o de la clase \textit{Message} (llegan del mediador.)
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	@Override
	public Receive createReceive() {
		return receiveBuilder()
		.match(String.class, message -> { /* FROM CLIENT */ })
		.match(Message.class, message -> { /* FROM OTHER USERS */ })
	}
	\end{lstlisting}
	
	El primer mensaje del cliente (el de conexión) provoca la subscripción de dicho usuario a la sala de chat que ha definido:
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	this.mediator.tell(
		new DistributedPubSubMediator
			.Subscribe(this.chatName, getSelf()),
		getSelf()
	);
	\end{lstlisting}
	
	De forma previa a esta subscripción, se valida que el nombre del usuario no está repetido. De ser así, el actor se \textit{suicida} (mandandose una \textit{PoisonPill} a sí mismo) y cierra la conexión con el cliente:
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	self().tell(PoisonPill.getInstance(), self());
	\end{lstlisting}
	
	\item \textbf{Re-envío de mensajes}: Cómo hemos definido antes, la entidad \textit{User} recibe dos tipos de mensajes:
	
	\begin{itemize}  
		\item Los mensajes del cliente (\textit{String}) el cual llega através del Websocket. Este se publica haciendo uso del mediador para distribuirlo al resto de usuarios en la sala de chat:
		
		\begin{lstlisting}[language=Java]
		// /app/actors/User.java
		mediator.tell(
			new DistributedPubSubMediator
				.Publish(this.chatName, message),
			getSelf()
		);
		\end{lstlisting}
		
		
		\item Los mensajes de otros usuarios (\textit{Message)}  son directamente re-enviados al cliente por Websocket (usando el actor que representa esta conexión):

		\begin{lstlisting}[language=Java]
		// /app/actors/User.java
		out.tell(message.getJson().toString(), self());
		\end{lstlisting}
		
	\end{itemize}
	
	\item \textbf{Desconexión}: Cuando el usuario cierra la conexión WebSocket, se ejecuta el método postStop() del User correspondiente, que se encarga de dar de baja al usuario de su sala de chat.
	
	\begin{lstlisting}[language=Java]
	// /app/actors/User.java
	mediator.tell(
		new DistributedPubSubMediator
			.Unsubscribe(this.chatName, getSelf()),
		getSelf()
	);
	\end{lstlisting}
	
	
	
\end{itemize}

\pagebreak

\textbf{Despliegue en clúster}

La entidad mediadora (\textit{mediator}) es la que nos proporciona la capacidad de comunicarnos con usuarios de otros nodos situados en otras máquinas. Akka junto al framework Play nos abstrae  de la lógica necesaria para esta comunicación, pero debemos declarar uno o varios \textit{seed-nodes} en el archivo \textit{/conf/application.conf} para crear nuestro clúster. Estos \textit{seed-nodes} ó nodos semilla en español identifican a una aplicación ya lanzada a la que una nueva aplicación puede unirse para formar un clúster.

\begin{lstlisting}
// /conf/application.conf
cluster {
	seed-nodes = [
		"akka.tcp://application@127.0.0.1:8000"
	]
}
\end{lstlisting}

El uso de \textit{seed-nodes} nos garantiza que al arrancar una nueva máquina con un nuevo nodo no se formarán islas en el clúster (nodos sin ninguna conexión con el resto).

Para desplegar 2 ó más nodos en AWS basta con lanzar una máquina (sin necesidad de declarar \textit{seed-nodes}) y obtener su dirección IP (privada). Los siguientes nodos deberán contener esta dirección entre sus \textit{seed-nodes} o declararlo como semilla al lanzarlo.

\begin{lstlisting}[language=bash]
	./webchat-1.0/bin/webchat \
	 	-Dakka.cluster.seed-nodes.0=akka.tcp://application@${SEED}:8000
\end{lstlisting}

Para facilitar el desplegado del clúster se facilita un script en python que automatiza todos los pasos necesarios. Para más detalles, consultar el fichero README.md\footnote{\url{https://github.com/TFG-DistributedWebChat/Akka-DistributedWebChat/blob/master/README.md}} del repositorio de Akka.

\textbf{Problemas en el desarrollo}

El mayor desafío era comprender cómo hacer evolucionar una aplicación monolítica a una distribuida. A partir de la documentación fué sencillo probar la aplicación haciendo uso de dos nodos en local, pero para desplegar estos nodos en AWS era necesario definir y abrir los puertos necesarios para que las máquinas pudieran comunicarse. Este despliegue require un gran número de pasos que dan lugar fácilmente a errores. La solución, tanto para Akka cómo para el resto de aplicaciones a este problema ser resolvió automatizando este despliegue, tal y cómo se ha comentado anteriormente.

\subsection{Vertx}

El código de esta aplicación se puede encontrar en un repositorio en GitHub de la organización antes mencionada bajo en nombre de \textit{Vertx-DistributedWebChat}\footnote{\url{https://github.com/TFG-DistributedWebChat/Vertx-DistributedWebChat}}

\textbf{Diseño y arquitectura}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/diagrams/Vertx-Diagram.png}
	\caption{Arquitectura de la aplicación de Vertx}
	\label{figura:vertx_ds}
\end{figure}


En el caso de esta aplicación, el funcionamiento y la arquitectura (Ver figura~\ref{figura:vertx_ds}) de la aplicación es muy similar a la versión monolítica ya que lo único que se distribuye es el bus de eventos.

La aplicación se compone de:
\begin{itemize} 
	\item Un \textit{ChatManager}, un Verticle que se ocupa de la recepción de mensajes por parte de los clientes, su posterior distribución y la gestión de los usuarios (creación y eliminación).

	\item Varios \textit{User}, Verticles que representan a cada usuario de la aplicación, que se encargan de almacenar la conexión WebSocket con su cliente para enviarle mensajes.
\end{itemize} 


\textbf{Funcionamiento}

\begin{itemize}  
	\item \textbf{Conexión}: Cuando un usuario inicia la conexión WebSocket, al contrario de otras aplicaciones, no se realiza ninguna acción más que proporcionar un handler para los mensajes. Cuando el cliente manda el mensaje de conexión, si el nombre no existe, se crear un nuevo User y se incluye en el contexto de la aplicación, guardando su id de Verticle en un mapa cuya clave es el nombre, tal y cómo podemos apreciar en el código a continuación:
	
	\begin{lstlisting}[language=Java]
	// /src/main/java/com/globex/app/ChatManager.java
	vertx.deployVerticle(user, res -> {
		if (res.succeeded()) {
			//Save the deploymentID to later remove the verticle
			users.put(name, res.result());
		} else {
			System.err.println("Error at deploy User");
		}
	});
	\end{lstlisting}
	
	\item \textbf{Re-envío de mensajes}: El chat manager es el encargado de recibir los mensajes de los clientes, publicándolos en el EventBus con la dirección igual a la sala de chat.
	
	\begin{lstlisting}[language=Java]
	// /src/main/java/com/globex/app/ChatManager.java
	vertx.eventBus().publish(message.getString("chat"), message);
	\end{lstlisting}
	
	Por otro lado, cuando un User es incluido en el contexto de la aplicación, se suscribe a su chat para recibir los mensajes dirigidos a esa sala y re-enviar a su cliente dichos mensajes. En el fragmento de código a continuación podemos apreciar esta subscripción y el callback que se ejecuta al recibir un mensaje:
	
	\begin{lstlisting}[language=Java]
	// /src/main/java/com/globex/app/User.java
	// Listen for messages from his chat
	this.handler = vertx.eventBus().consumer(chat).handler(data -> {
		try{
			// Try to send the message
			this.wss.writeFinalTextFrame(data.body().toString());
		}catch(IllegalStateException e){
			// The user is offline, so I delete it.
			this.handler.unregister();
			vertx.eventBus().publish("delete.user", name);
			wss.close();
		} 
	});
	\end{lstlisting}

	\item \textbf{Desconexión}: Se produce cuando User no es capaz de enviar un mensaje a su cliente. Publica su borrado en el EventBus y cierra la conexión. El evento de borrado es capturado por el ChatManager, que da de baja al User.

	\begin{lstlisting}[language=Java]
		// /src/main/java/com/globex/app/ChatManager.java
		vertx.undeploy(users.get(user_name));
		users.remove(user_name);
	\end{lstlisting}
	
	
\end{itemize}

\textbf{Despliegue en clúster}

La entidad de esta tecnología que nos permite distribuir el envío de mensajes es el \textit{Event Bus} o bus de eventos. Este recurso puede utilizarse tanto en local cómo en distribuido de forma análoga. Para distribuirse, hace uso de Hazelcast\footnote{\url{https://hazelcast.com/}} y es necesario declarar almenos un nodo semilla (al igual que Akka) aunque también permite definir una interfaz de red bajo la que descubrir los nodos. Para este proyecto hemos usado la primera opción para descubrir el nodo semilla mediante TCP simplemente añadiendo la dirección de un nodo (previamente lanzado en otra máquina) en el archivo de configuración \textit{cluster.xml}:

\begin{lstlisting}[language=XML]
<tcp-ip enabled="true">
	<interface>172.31.34.96</interface>
</tcp-ip>
\end{lstlisting}

Es posible configurar Hazelcast para que trabaje junto a un security group de AWS, pero resulta bastante más compleja.

Para desplegar el clúster se ha hecho uso de nuevo de un script en python que automatiza todos los pasos necesarios. Para más detalles, consultar el fichero README.md\footnote{\url{https://github.com/TFG-DistributedWebChat/Vertx-DistributedWebChat/blob/master/README.md}} del repositorio de Vertx.

\textbf{Problemas en el desarrollo}

Sin duda el mayor reto fué comprender cómo funciona Hazelcast a nivel de TCP-IP y que requiere de la IP privada y no la pública (otra tecnología que veremos más adelante, RabbitMQ, es capaz de resolver incluso a partir de DNS) lo que dió lugar a bastantes problemas ya que la documentación para clúster era bastante pobre y los ejemplos no proporcionaban la guía necesaria para hacer un uso correcto de esta funcionalidad.

De forma adicional, Vert.x arrastraba del proyecto anterior un grave problema de memoria, siendo la tecnología que más uso hacia de este recurso. Tras trabajar con RabbitMQ (que también sufria de problemas similares y se hayó el problema) se llegó a la conclusión de que probablemente algun recurso registrado en el EventBus no estaba siendo liberado (pensando que simplemente con expulsar al actor del sistema, se borraba cualquier referencia). Finalmente se detecto que recurso era: un manejador (\textit{handler}) que el usuario registraba para poder subscribirse a los mensajes de un chat. Para darle de baja solo era necesario guardar una referencia a este manejador y liberarlo cuando se cerrase la conexión Websocket:

\begin{lstlisting}[language=Java]
	this.handler.unregister();
\end{lstlisting}


\subsection{Spring + RabbitMQ}

El código de esta aplicación se puede encontrar en un repositorio en GitHub de la organización antes mencionada bajo en nombre de \textit{SpringBoot-RabbitMQ-DistributedWebChat}\footnote{\url{https://github.com/TFG-DistributedWebChat/SpringBoot-RabbitMQ-DistributedWebChat}}

\textbf{Diseño y arquitectura}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{img/diagrams/Spring-Diagram.png}
	\caption{Arquitectura de la aplicación de SprinBoot+RabbitMQ}
	\label{figura:rabbit_ds}
\end{figure}

Cómo podemos apreciar en la figura~\ref{figura:rabbit_ds}, parte de la lógica del sistema se encuentra fuera de la aplicación de Java, en el servidor de RabbitMQ, será necesario por tanto una libreria/cliente AMQP para poder conectarnos a dicho servidor.

Utilizaremos una cola para cada usuario y un único \textit{Exchange} para todo el sistema. De esta forma, los usuarios comunicarán al \textit{Exchange} sus mensajes y este se encargará de hacerlos llegar a las colas de los usuarios en su misma sala.

La aplicación de Spring hace uso de la anotación @ServerEndpoint sobre la clase User, que convierte a dicha clase en un punto de entrada para la conexión WebSocket. Permite a la clase implementar métodos bajo las anotaciones:

\begin{itemize}

\item \textbf{@OnOpen}: Se ejecuta cuando el usuario establece la conexión

\item \textbf{@OnMessage}: Se ejecuta cada vez que el usuario manda un mensaje

\item \textbf{@OnClose}: Se ejecuta cuando la conexión WebSocket se cierra

\item \textbf{@OnError}: Se ejecuta cada vez que sucede un error en la conexión, capturándolo

\end{itemize}

Estas anotaciones permiten tener un control sencillo del flujo de la aplicación y de los eventos que requiere.

Cada vez que un cliente se conecta, se crea una instancia de User que se encargará de recoger los eventos de ese usuario en concreto. Esto es posible gracias a SpringBoot, que se encarga de servir esta clase como un componente reutilizable bajo la anotación \textit{@Bean} en WebChatSpringBootApplication (que actúa como archivo de configuración):

\begin{lstlisting}[language=Java]
	// /src/main/java/com/chat/WebChatSpringBootApplication.java
	@Bean
	public User reverseWebSocketEndpoint() {
		return new User();
	}
\end{lstlisting} 

Todas las anotaciones utilizadas pertenecen a la librería WebSocket de Java\footnote{\url{https://mvnrepository.com/artifact/javax.websocket/javax.websocket-ap}}.

La clase \textit{User} implementa tambien la interfaz (a partir de una clase intermedia, \textit{UserConsumer}) \textit{Consumer}, que le permite ser subscriptor a una cola de RabbitMQ.

Por otro lado, cada aplicación/nodo cuenta con un ChatManager, una clase que implementa el patron \textit{Singleton}\footnote{\url{https://es.wikipedia.org/wiki/Singleton}} y a la que los User tienen acceso. Esta clase permite a un User subscribirse a un topic (nombre de la sala de chat). El Chat Manager se encarga de crear la conexión.

\textbf{Funcionamiento}

\begin{itemize}
	\item \textbf{Conexión}: Al iniciarse la conexión, se crea un objeto de la clase \textit{User} que manejara dicha conexión. Se ejecutará el método \textit{@OnOpen}, que obtiene una referencia al \textit{ChatManager}. El mensaje de conexión, en cambio, es capturado por el método bajo la anotación \textit{@OnMessage}, que tras validar que el usuario asociado a esa sesión no tiene aún atributos como name o chat, comprueba que el nombre sea único y se los asigna. Se informa al \textit{ChatManager} para que se le incluya y le subscriba a su sala de chat, asignandole al \textit{User} su conexión con el \textit{Exchange}.
	
	\item \textbf{Re-envío de mensajes}: Un \textit{User} recibirá mensajes de dos formas:
	\begin{itemize}
		\item Un nuevo mensaje del cliente llega desde el WebSocket y ejecuta el método \textit{handleMessage()}. Este mensaje será enviado al \textit{Exchange}, que se ocupará de distribuir dicho mensaje a todas las colas de otros usuarios, siendo el topic de este envío su sala de chat.
\begin{lstlisting}[language=Java]
this.channel.basicPublish(EXCHANGE_NAME, chat, null, message.getBytes());
\end{lstlisting} 
		\item Un nuevo mensaje procedente de su cola y que recoge en el metodo \textit{sent()} que lo envía directamente por WebSocket al cliente.
\begin{lstlisting}[language=Java]
session.getBasicRemote().sendText(message);
\end{lstlisting} 
	\end{itemize}
	\item \textbf{Desconexión}: Cúando un cliente se desconecta (se cierra su conexión Websocket), se ejecuta el método bajo la anotación \textit{@OnClose}, que cierra la conexión con RabbitMQ de ese usuario e informa al \textit{ChatManager} para que le elimine del registro.
\end{itemize}

\textbf{Despliegue en clúster}

En este caso, la aplicación de Spring no se distribuye, si no que es el servicio externo, RabbitMQ, el que lo hará. Los pasos para formar un clúster RabbitMQ son algo más complejos que en el resto de aplicaciones:

\begin{itemize}
	\item Arrancar el servicio RabbitMQ en ambas máquinas, deben estar en la misma versión y compartir una clave denominada \textit{erlang-cookie} (un archivo de configuración).
	\item Detener RabbitMQ en una de las máquinas, ejecutar:
	\begin{lstlisting}[language=Bash]
	rabbitmqctl join_cluster rabbit@ip-${MASTER-IP}
	\end{lstlisting} 
	siendo MASTER-IP la IP de la máquina que no hemos detenido. Arrancamos de nuevo RabbitMQ y ya se habrá formado el clúster
\end{itemize}

RabbitMQ permite usar plugins de mucha utilidad. Para esta aplicación ha sido de especial interés el plugin \textit{rabbitmq-management} que nos permite acceder desde el navegador a diferentes métricas de nuestro clúster: número de colas, conexiones, exnchanges, además del uso de memoria.

Una vez nuestro clúster esta desplegado, basta con lanzar nuestra aplicación de Spring en cada máquina.


\textbf{Problemas en el desarrollo}

En contraste a las otras tecnologías que son toolkits completos, con RabbitMQ y Spring nos encontramos el problema de lidiar con un servicio externo. La mayor dificultad de esta aplicación fué distribuir los nodos de RabbitMQ, comprender la importancia de la \textit{erlang-cookie} y manejar la unión de nodos, que si no se seguian los pasos en un orden concreto, era imposible de realizar. Aunque la documentación oficial es muy completa, sin duda ha sido gracias a la comunidad y a la lectura de numerosos ejemplos de terceros lo que ha hecho posible la comprensión de este proceso.

Otro problema que surgió a raiz de un desconocimiento de la gestión de recursos del cliente AMQP fué el no cerrar apropiadamente las conexiones de los usuarios. Esto provocaba un aumento constante de la memoria RAM utilizada por la máquina, que para las pruebas más exigentes provocaba la parada del servicio. Gracias al plugin antes mencionado, se pudo monitorizar los nodos para detectar este problema, haciendo los cambios pertinentes con resultados satisfactorios.

\subsection{Spring + Hazelcast}

El código de esta aplicación se puede encontrar en un repositorio en GitHub de la organización antes mencionada bajo en nombre de \textit{SpringBoot-RabbitMQ-DistributedWebChat}\footnote{\url{https://github.com/TFG-DistributedWebChat/SpringBoot-RabbitMQ-DistributedWebChat}}

\textbf{Diseño y arquitectura}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/diagrams/Spring-Hazelcast-Diagram.png}
	\caption{Arquitectura de la aplicación de SpringBoot+Hazelcast}
	\label{figura:hazelcast_ds}
\end{figure}


Al contrario que la aplicación de Spring junto a RabbitMQ, esta aplicación usa una arquitectura (Ver figura~\ref{figura:hazelcast_ds}) más similar a Vert.x (ambos usan Hazelcast), pero es muy parecida en cuanto a código se refiere a la primera, por lo que se mencionaran los cambios realizados.

La aplicación hace uso de la anotación @ServerEndpoint sobre la clase User de nuevo, no varía su implementación salvo para el envío y recepción de mensajes de otros usuarios.

Cada \textit{User} implementa la interfaz \textit{MessageListener} que le permite subscribirse y recibir mensajes de Hazelcast. El \textit{ChatManager}, de nuevo único para la aplicación, se limitara a gestionar las altas y bajas de usuarios, manteniendo una referencia a la instancia de Hazelcast para ello.

\textbf{Funcionamiento}

El funcionamiento general de la aplicación es muy similar al de su versión con RabbitMQ.

\begin{itemize}
	\item \textbf{Conexión}: Al iniciarse la conexión, se crea un objeto de la clase \textit{User} que manejara dicha conexión. Se ejecutará el método \textit{@OnOpen}, que obtiene una referencia al \textit{ChatManager}. El mensaje de conexión, en cambio, es capturado por el método bajo la anotación \textit{@OnMessage}, que tras validar que el usuario asociado a esa sesión no tiene aún atributos como name o chat, comprueba que el nombre sea único y se los asigna. Se informa al \textit{ChatManager} para que le subscriba a su sala de chat, devolviendole un \textit{topic}, una referencia a su sala de chat para poder interactuar con ella. Además, se guarda junto a su nombre un identificador único con el que poder darse de baja más adelante.
	
	\item \textbf{Re-envío de mensajes}: Un \textit{User} recibirá mensajes de dos formas:
	\begin{itemize}
		\item Un nuevo mensaje del cliente llega desde el WebSocket y ejecuta el método \textit{handleMessage()}. Este mensaje será enviado a través de la referencia del topic a todos los usuarios subscritos a él.
		\begin{lstlisting}[language=Java]
		@OnMessage
		public void handleMessage(Session session, String message){
			// ...
			this.topic.publish(message);
			// ...
		}
		\end{lstlisting} 
		\item Un nuevo mensaje de su topic y que recoge en el metodo \textit{onMessage()} que lo envía directamente por WebSocket al cliente.
		\begin{lstlisting}[language=Java]
		@Override
		public void onMessage(Message<String> message) {
			this.send(message.getMessageObject());
		}
		\end{lstlisting} 
	\end{itemize}
	\item \textbf{Desconexión}: Cúando un cliente se desconecta (se cierra su conexión Websocket), se ejecuta el método bajo la anotación \textit{@OnClose}. Se informa al \textit{ChatManager} para que le tramite la baja y le desuscriba del topic.
\end{itemize}

\textbf{Despliegue en clúster}

El despliegue en clúster es idéntico al de la aplicación de Vert.x. Al usar Hazelcast, no se distingue al hacer uso de el tanto en local cómo en distribuido. Sólo es necesario definir el archivo de configuración de hazelcast, al igual que en Vert.x.

Se proporciona, al igual que en otras tecnologías, los scripts necesarios para automatizar este proceso

\textbf{Problemas en el desarrollo}

Fué relativamente sencillo construir y lanzar esta aplicación en un clúster tras comprender cómo funciona Hazelcast en la aplicación de Vert.x. Se intentó automatizar aún más su despligue haciendo uso de los servicios de AWS, pero se llegó a la conclusión que era mucho más laborioso y no aportaba ningun valor añadido.

\section{Pruebas}

Las aplicaciones desarrolladas carecen de pruebas unitarias o de integración propias, comparten un cliente común capaz de probarlas de forma completa y distribuida.

A lo largo de este apartado hablaremos de este cliente, su implementación y de sus características.

El código de esta aplicación se puede encontrar en un repositorio en GitHub de la organización antes mencionada bajo en nombre de \textit{DistributedWebChatClient}\footnote{\url{https://github.com/TFG-DistributedWebChat/DistributedWebChatClient}}

\subsection{Cliente heredado}
Al igual que las aplicaciones, se contaba con un cliente de pruebas heredado del proyecto anterior. Este cliente usaba JUnit junto a herramientas de testing de Vert.x para probar las distintas aplicaciones de chat. El funcionamiento de este cliente era el siguiente:

\begin{enumerate}
	\item Se escribe un archivo de configuración dónde se definia cada aplicación a probar en local y testeaba una tras otra.odía probarse tanto cómo si ya estaba lanzada cómo si no, en este caso, el propio cliente era capaz de lanzarla.
	\item Se abre un cliente web en el navegador por defecto dónde van apareciendo los resultados.
	\item Generaba X clientes para Y salas de chat, de forma que cada cliente enviaba (además de su mensaje de conexión) 500 mensajes al resto de usuarios en un periodo de 5 segundos.
	\item El mensaje contiene el momento (en milisegundos) en el que es enviado el mensaje. Cada cliente va recibiendo los mensajes y almacenando el tiempo que tardan en llegar (momento actual - momento que trae el mensaje).
	\item Cuando todos los clientes han recibido todos los mensajes (sin pérdidas) se divide el tiempo total entre el número total de mensajes (Nº usuarios x Nº usuarios x 500). Este proceso se repite 10 veces de forma identica para obtener mayor homogeneidad. Al terminar estas iteraciones, en envíaba el resultado al cliente web.
	\item De forma paralela, se recogen métricas de uso de CPU y de memoria para ese proceso.
\end{enumerate}

Los pasos 3, 4, 5 y 6 se repiten para cada aplicación con distinto número de clientes y salas de chat.

\subsection{Desarrollo e implementación}

El cliente descrito en la sección anterior estaba límitado a aplicaciones en local, aunque era capaz de medir la latencia en máquinas externas es necesario incluir una forma de medir el resto de métricas.

Dado que usar archivos de test dificultaba bastante seguir el flujo de la aplicación, se optó por re-escribir dicho cliente desde 0 (incluyendo el cliente web), manteniendo las funcionalidades principales.

Entre los objetivos de esta re-implementación se encuentran:

\begin{itemize}
	\item Re-estructurar la ejecución de los casos de prueba para que funcione cómo una aplicación normal y no cómo un proceso de test.
	\item Permitir obtener métricas de máquinas remotas (métrica por nodo/máquina).
	\item Notificar al usuario de la aplicación web del progreso de las iteraciones.
	\item Re-escribir el cliente web de forma que permita una nueva forma de entrada de configuración (en lugar de en un archivo)y permita mostrar las diferentes métricas por nodos.
\end{itemize}

\pagebreak
\textbf{Re-estructuración}

En este primer paso, re-escribiremos la aplicación de Java para que no haga uso de archivos de test, aunque seguiremos usando el toolkit Vert.x para gestionar los callbacks de las pruebas.

Para comunicar los distintos componentes de la aplicación (incluso en el cliente web) usaremos el EventBus de Vert.x. Los componentes principales de la aplicación son:

\begin{itemize}
	\item \textbf{TestResultsServer}: un sencillo servidor de Vert.x que nos permite ofrecer un cliente web con una conexión directa con él. Es el encargado de lanzar al ClientManager dentro del contexto de Vert.x. Del cliente, el cual detallaremos más a delante, llegará la configuración concreta de las pruebas que se quieren realizar, que enviará al \textit{ClientManager}
	\item \textbf{ClientManager}: un actor de Vert.x que atenderá las peticiones de nuevas pruebas y las ejecutará, comunicando los resultados directamente al cliente web mediante el bus de eventos.
	\item \textbf{ClientGenerator}: un actor de Vert.x que recibirá un caso de prueba a realizar por parte del \textit{ClientManager} y lo ejecutará, obteniendo las diferentes métricas.
\end{itemize}

La configuración que recibe el ClientManager se estructura cómo un JSON. Un ejemplo de esta configuración sería la siguiente:

\begin{lstlisting}[language=Javascript]
	{
		name: "RabbitMQ",
		address: "127.0.0.1",
		port: 5000,
		pem: "TFG.pem",
		isDistributed: true,
		nodes: [
			"ec2-34-244-127-84.eu-west-1.compute.amazonaws.com",
			"ec2-34-243-28-134.eu-west-1.compute.amazonaws.com"
		],
		cases: [
			{ numChats: 1, numUsers: 10 },
			{ numChats: 2, numUsers: 20 },
			{ numChats: 3, numUsers: 25 }
		]
	}
\end{lstlisting}

dónde:

\begin{itemize}
	\item \textit{name} es el nombre que daremos a la aplicación
	\item \textit{address} es la dirección del punto de entrada del proxy.
	\item \textit{port} es el puerto en el cual escucha el proxy.
	\item \textit{pem} es el nombre del archivo PEM que utilizaremos más adelante.
	\item \textit{isDistributed} nos indica si la aplicación es distribuida o local.
	\item \textit{nodes} son las direcciones DNS de los nodos concretos de la aplicación (en el caso de ser esta distribuida)
	\item \textit{cases} son los casos para los que queremos probar nuestra aplicación. Se compone de una tupla con el número de salas de chat que habrá y el número de usuarios por cada una de estas salas.
\end{itemize}

A partir de esa configuración, el \textit{ClientManager}   ejecutará cada caso 10 veces. En cada iteración de del caso de prueba se hará uso de un \textit{ClientGenerator}, que es el encargado de generar los clientes que interactuarán con la aplicación. Este \textit{ClientGenerator} resultaría muy similar en cuanto a funcionamiento al heredado, siendo capaz de recoger la latencia media de cada caso. 

Al acabar cada iteración, se devuelve el resultado de la misma al \textit{ClientManager} que lo seguirá completando con las iteraciones posteriores y lanza un evento en el bus de eventos dónde informa de la iteración completada.

De esta forma ya tendriamos un cliente de pruebas sencillo y funcional. 

El siguiente paso sería incluir una recogida de métricas (uso de CPU y memoria) para cada nodo definido en la configuración. Para hacerlo lo más homogéneo posible, recogeremos esta métricas para la máquina completa (cuyo uso es exclusivo para ejecutar la aplicación de chat). Las máquinas que utilizaremos estarán basadas en Linux, concretamente en Ubuntu, por lo que podremos usar los siguientes scripts para obtener las métricas por nodo/máquina:

\textbf{Obtención de uso de CPU:}
\begin{lstlisting}[language=Bash]
#!/bin/bash
ssh -i pems/$PEM $MACHINE top -b -n 2 | grep "Cpu(s):" | awk '{ print $2 }'
\end{lstlisting}

\textbf{Obtención de uso de memoria:}
\begin{lstlisting}[language=Bash]
#!/bin/bash
ssh -i pems/$PEM $MACHINE free -m | grep "Mem:" | awk '{ print $3 }'
\end{lstlisting}

Dónde \textit{PEM} es el nombre del archivo .pem\footnote{Un archivo .pem nos permite realizar una conexión ssh con una máquina remota y ejecutar comandos sobre ella.} definido en la configuración y MACHINE será la dirección de la máquina también definida en la configuración. Este archivo debe estar presente en la carpeta \textit{/pems} antes de iniciar la aplicación.

En la aplicación será el \textit{ClientGenerator} la entidad que hará uso de estos scripts desde Java. En cada iteración de cada caso, esta entidad generará un hilo de ejecución que ejecutará estos scripts de forma periodica (cada segundo). Tras finalizar la iteración, se hará la media de cada métrica para incluirlo en el resultado.

Por último, habría que re-escribir el cliente web (escrito en Angular) para soportar este nuevo servidor las opciones que ofrece.

Para ello se proporcionará una interfaz en la que poder introducir la configuración completa cómo se puede apreciar en la figura~\ref{figura:web1}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.25]{img/screenshots/web1.png}
	\caption{Cliente web - Pantalla de configuración de la prueba}
	\label{figura:web1}
\end{figure}


Una vez se introduzcan la configuración de las pruebas a realizar, la siguiente pantalla deberá visualizar el progreso de la misma mientras se van mostrando los resultados, incluyendo las métricas de CPU y memoria por nodo (Ver figura~\ref{figura:web2}).

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.25]{img/screenshots/web2.png}
	\caption{Cliente web - Informe de progreso y métricas}
	\label{figura:web2}
\end{figure}


Al finalizar las pruebas, obtendremos los datos en formato JSON.

La arquitectura de nuestro sistema de pruebas resultante puede apreciarse en la figura~\ref{figura:arquitec}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/diagrams/TestArquitecture.png}
	\caption{Arquitectura del sistema}
	\label{figura:arquitec}
\end{figure}


Esta aplicación nos permite obtener las métricas de latencia, uso de CPU y memoria de una aplicación distribuida. Una vez tengamos los resultados de varias aplicaciones, se pueden comparar en un sencillo dashboard interactivo (Ver figura~\ref{figura:web3}).

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.25]{img/screenshots/web3.png}
	\caption{Cliente web - Dashboard comparativo}
	\label{figura:web3}
\end{figure}


\subsection{Funcionamiento}

A continuación se detalla el flujo del funcionamiento de la aplicación (Ver figura~\ref{figura:func}):

\begin{itemize}
	\item \textbf{Paso 0:} Antes de comenzar, nos aseguramos de que las máquinas y el proxy esten operativos, situamos el archivo PEM bajo la carpeta \textit{/pems} del proyecto de la aplicación de pruebas y lanzamos la aplicación. Esto abrirá automaticamente el cliente en nuestro navegador.
	\item \textbf{Paso 1:} Introducimos la configuración de las pruebas que queremos realizar (configuración del proxy, los nodos y los casos) en el navegador y los enviamos al servidor.
	\item \textbf{Paso 2:} El \textit{ClientManager} recibe la configuración, crea un \textit{ClientGenerator} y lo lanza junto a un caso de prueba.
	\item \textbf{Paso 3:} El \textit{ClientGenerator} genera tantos clientes Websocket cómo define la configuración para que se conecten a la aplicación a través del proxy (Estos clientes pueden pertenecer a salas diferentes). A la vez, de forma periodica, recoge las distintas métricas para cada nodo que forma la aplicación distribuida a probar.
	\item \textbf{Paso 4:} Tras recoger los tiempos de respuesta y las métricas de CPU y memoria, se guardan en un resultado y se devuelven en un callback al \textit{ClientManager}
	\item \textbf{Paso 5:} El \textit{ClientManager} recibe el callback y emite un evento de finalización de la iteración. Este evento es capturado por el cliente web que muestra el progreso de ese caso por pantalla.
	
	Los pasos 2-5 se repiten para cada iteración de cada caso.
	
	\item \textbf{Paso 6:} Cuando no hay mas casos que probar, el \textit{ClientManager} lanza un evento de finalización, de nuevo capturado por el cliente web que provoca la descarga de los resultados en un JSON
	
	\item \textbf{Paso 7:} Una vez hemos probado varias aplicaciones, situamos dichos archivosen la carpeta \textit{src/main/resources/webroot/results}, los declaramos en el archivo \textit{index.json}, relanzamos la aplicación de pruebas vamos a la ruta \textit{/comparative} para visualizar la comparativa por cada métrica entre las distintas aplicaciones para distintos criterios (número de salas de chat y número de máquinas).
	
\end{itemize}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/diagrams/funcionamiento.png}
	\caption{Funcionamiento de la aplicación de pruebas}
	\label{figura:func}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 		   5. Estudio comparativo             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Estudio comparativo}
\label{sec:comparativa} 

Una vez disponemos de todas las aplicaciones desarrolladas y una herramienta para probarlas, llega el momento de realizar la comparativa entre tecnologías.

Las aplicaciones han usado como máquinas para albergar sus nodos instancias EC2 de AWS, concretamente el modelo t2.micro \footnote{\url{https://aws.amazon.com/es/ec2/instance-types/}} debido a que es el único que entra dentro de la capa gratuita y no es necesario probarlas en máquinas con mayor capacidad para compararlas. Esta instancia cuenta con 1 CPU y 1 GB de memoria RAM. El sistema operativo elegido para las instancias ha sido Ubuntu 16.04 por su estabilidad, la comunidad detrás ante cualquier problema y el hecho de que las pruebas en local se realizaron en el mismo sistema operativo.

En lugar de usar una máquina remota, se ha usado HAProxy en la misma máquina en la que se lanza el cliente de pruebas, un sistema Ubuntu 16.04 con 16 GB de memoria RAM y 4 procesadores.

Los casos definidos para esta prueba han sido:

\begin{itemize}
	\item 1 sala de chat con 10, 20, 30, 40, 50 y 60 usuarios
	\item 2 salas de chat con 20, 25, 30 y 35 usuarios en cada una
	\item 4 salas de chat con 10, 12, 15 y 17 usuarios en cada una
\end{itemize}

Se han repetido los casos para 2, 3 y 4 nodos.

Debido a que las máquinas remotas son menos potentes que la utilizada para el escalado vertical del proyecto anterior, se ha reducido los mensajes por usuario de 500 a 100.

Desglosaremos la comparativa en las distintas métricas que vamos a medir: latencia, uso de CPU y uso de memoria, además de comparar la dificultad/complejidad del desarrollo. Una vez realizado el estudio, procederemos a formular una serie de conclusiones.

Para interpretar las gráficas que usaremos para mostrar los resultados de las pruebas es importante comprender su estructura:

Cada gráfica contiene los resultados de una métrica concreta para un número de salas concreto.

En el eje Y encontraremos la métrica estudiada

En el eje X encontraremos el número de mensajes que se han enviado en total. Este número se obtiene de la siguiente fórmula:

$$
N_odeMensajes = (N_0UsuariosPorSala)^2 * N_0DeSalas * 100
$$

Junto a cada métrica, se comentarán los resultados del estudio comparativo previo para valorar la diferencia entre una aplicación en un solo nodo o en varios.

\section{Latencia}

Para nuestro caso de estudio, podemos definir la latencia o tiempo de respuesta (Ver figrua~\ref{figura:latency}) como el retardo en milisegundos producido por la demora en la propagación de los mensajes.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/latency.png}
	\caption{Latencia}
	\label{figura:latency}
\end{figure}


Conviene recordar que:
\begin{itemize}
	\item Para obtener esta métrica, el mensaje recoge en su contenido el momento (en ms) en el que es enviado, calculándose la diferencia a su llegada, que será el retardo.
	\item Los resultados que podemos encontrar en las gráficas son la media aritmética de los N mensajes enviados en un total de 10 iteraciones.
\end{itemize}

A continuación se muestran los resultados de latencia para distinto número de salas de chat en distinto número de nodos:

\subsection{Latencia en 2 nodos}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/1roomtime.png}
	\caption{1 room(s) - Time - 2 nodes}
	\label{figura:lat2-1}
\end{figure}

Observamos una clara diferencia (Ver figura~\ref{figura:lat2-1}) entre las aplicaciones basadas en actores que las de SpringBoot, obteniendo las primeras resultados significativamente mejores.

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/2roomtime.png}
	\caption{2 room(s) - Time - 2 nodes}
	\label{figura:lat2-2}
\end{figure}

Al aumentar en número de chats a 2 (Ver figura~\ref{figura:lat2-2}), no parece haber grandes cambios respecto a la anterior gráfica. Destacamos que a un menor número de mensajes (180.000 frente a 250.000) la aplicación de SpringBoot+RabbitMQ empeora bastante haciendo evidente que aumentar el número de \textit{topics} en RabbitMQ aumenta la latencia global.

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/4roomtime.png}
	\caption{4 room(s) - Time - 2 nodes}
	\label{figura:lat2-4}
\end{figure}

Con 4 salas (Ver figura~\ref{figura:lat2-4}) de chat el mayor cambio se produce en la aplicación de SpringBoot+Hazelcast, que reduce considerablemente su latencia hasta equipararse con Akka y Vert.x (recordemos que Vert.x hace uso internamente de Hazelcast). Aunque el número de mensajes es sustancialmente menor, para 90.000 ofrece 836 ms de latencia, por los 2439 ms que ofrece para 80.000  mensajes en 2 salas de chat. 

\subsection{Latencia en 3 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/1roomtime.png}
	\caption{1 room(s) - Time - 3 nodes}
	\label{figura:lat3-1}
\end{figure}

Al aumentar el número de nodos de 2 a 3 (Ver figura~\ref{figura:lat3-1}) observamos ligeras mejoras en las aplicaciones de Vert.x y Akka, pero dónde realmente se nota esta nueva instancia es en las aplicaciones de SpringBoot, que reducen su latencia en 1/3.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/2roomtime.png}
	\caption{2 room(s) - Time - 3 nodes}
	\label{figura:lat3-2}
\end{figure}

En el caso de 2 salas de chat (Ver figura~\ref{figura:lat3-2}), la diferencia más significativa es la de Hazelcast, que al igual que ocurria en el caso de 4 salas de chat en 2 nodos, la latencia desciende de forma considerable hasta equipararse con Vert.x y Akka.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/4roomtime.png}
	\caption{4 room(s) - Time - 3 nodes}
	\label{figura:lat3-4}
\end{figure}

En este caso (Ver figura~\ref{figura:lat3-4}), vemos cómo el aumento de salas de chat hace que se solapen las aplicaciones de Vert.x y SpringBoot+Hazelcast en cuando a la métrica medida. RabbitMQ mejora discretamente al incluir este nodo extra.

\pagebreak

\subsection{Latencia en 4 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/1roomtime.png}
	\caption{1 room(s) - Time - 4 nodes}
	\label{figura:lat4-1}
\end{figure}

Al hacer uso de un nodo adicional (Ver figura~\ref{figura:lat4-1}), comprobamos de nuevo cómo los cambios más drásticos se producen en las aplicaciones de SpringBoot, especialmente en su variante con RabbitMQ, que ofrece una bajada de latencia a más de la mitad que en su versión con 2 nodos. Las aplicaciones de Akka y Vert.x siguen ofreciendo buenos resultados, reduciendo sensiblemente la latencia que el aumento de los nodos.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/2roomtime.png}
	\caption{2 room(s) - Time - 4 nodes}
	\label{figura:lat4-2}
\end{figure}

Haciendo uso de dos salas de chat (Ver figura~\ref{figura:lat4-2}), la única diferencia notable parece ser un peor resultado para la aplicación de SpringBoot+Hazelcast. Se revisó y se realizaron de nuevo las pruebas pero los resultados eran similares. Es posible que el número de instancias/nodos sea lo suficientemente grande para que se degrade las prestaciones de la aplicación y aumente la latencia. Esto ocurre, en mucha menor medida, en el resto de aplicaciones.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/4roomtime.png}
	\caption{4 room(s) - Time - 4 nodes}
	\label{figura:lat4-4}
\end{figure}

En este último caso (Ver figura~\ref{figura:lat4-4}), vemos cómo la latencia media de las aplicaciones se iguala hasta algo menos de 60.000 mensajes, manteniendose casi lineal la aplicación de Vert.x, aumentando ligeramente la de Akka y creciendo casi 4 veces las aplicaciones basadas en SpringBoot.

\subsection{Conclusión del estudio: Latencia}

Tras estudiar los distintos casos (combinaciones de salas de chat y número de instancias) podemos determinar que las aplicaciones que mejor escalan atendiendo a la latencia son las basadas en modelos de actores, Akka y Vertx, siendo esta última la que ofrece mejores resultados globales para todos los caso.

Por el contrario, las aplicaciones de SpringBoot ofrecen un peor escalado horizontal, aumentando considerablemente la latencia cuando aumenta el flujo de datos en la aplicación, aunque son las que más mejoran cuando se aumenta el número de instancias.

Podemos deducir que Hazelcast (tecnología sobre la que funciona la aplicación de SpringBoot con mismo nombre y la de Vert.x) ofrece altas prestaciones en cuanto a latencia se refiere, siendo capaz de mejorar los tiempos al sustituir una tecnología de cola de mensajes como es RabbitMQ.

\subsection{Restrospectiva: Latencia}

Para finalizar el estudio de la latencia, echemos un vistazo a los resultados del proyecto anterior (escalado vertical).

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{img/old/1roomtime.png}
	\caption{1 room(s) - Time - 1 node}
	\label{figura:old_latency}
\end{figure}

Cómo podemos observar en la figura~\ref{figura:old_latency}, los resultados en un solo nodo son completamente distintos. La aplicación de Vert.x ofrece los peores resultados con diferencia, mientras que en SpringBoot la latencia apenas aumenta aún cuando la carga de mensajes sobrepasa el millón. Cabe mencionar que la aplicación de SpringBoot no hace uso de ningun sistema externo o libreria para la distribución de mensajes, se gestiona a nivel de aplicación con llamadas a funciones.

Tras ver estos resultados, podemos afirmar que Vert.x es una tecnología pensada para distribuirse y no ofrece soluciones eficientes en lo que a latencia respecta para una aplicación monolítica. Por otro lado SpringBoot invierte este enunciado, siendo una solución monolítica sin apenas latencia pero sin utilidad a la hora de distribuirse, pues requiere de librerias externas que merman su eficiencia. Por último, mencionar que Akka resulta ser una buena tecnología en ambos casos.

\section{Uso de CPU}

Tal y como se ha desarrollado la obtención de métricas, el uso de CPU calculado es la media del uso de este recurso por nodo del clúster haciendo uso del comando top mediante SSH. Al probarse sobre máquinas de un único procesador, esta métrica no sobrepasará el 100\%.

\subsection{Uso de CPU en 2 nodos}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/1roomcpu.png}
	\caption{1 room(s) - CPU - 2 nodes}
	\label{figura:cpu2-1}
\end{figure}

Para el primer caso (Ver figura~\ref{figura:cpu2-1}) se aprecia cómo el uso de cpu de SpringBoot+RabbitMQ llega a duplicar el valor de las aplicaciones que usan Hazelcast. Estas últimas muestran un uso de CPU casi idéntico. El uso de este recurso en Akka aumenta en mayor medida que las aplicaciones de Hazelcast, pero sin sobrepasar a SpringBoot+RabbitMQ.

\pagebreak

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/2roomcpu.png}
	\caption{2 room(s) - CPU - 2 nodes}
	\label{figura:cpu2-2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/2nodes/4roomcpu.png}
	\caption{4 room(s) - CPU - 2 nodes}
	\label{figura:cpu2-4}
\end{figure}

El uso de memoria se mantiene estable en todas las aplicaciones para 2 y 4 salas de chat  (Ver figuras~\ref{figura:cpu2-2} y \ref{figura:cpu2-4}). Las basadas en Hazelcast mantienen resultados similares.

\pagebreak

\subsection{Uso de CPU en 3 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/1roomcpu.png}
	\caption{1 room(s) - CPU - 3 nodes}
	\label{figura:cpu3-1}
\end{figure}

En todas las tecnologías (Ver figura~\ref{figura:cpu3-1}) se observa un uso menor de este recurso, debido a la distribución de carga de usuarios entre los nodos.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/2roomcpu.png}
	\caption{2 room(s) - CPU - 3 nodes}
	\label{figura:cpu3-2}
\end{figure}

\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/4roomcpu.png}
	\caption{4 room(s) - CPU - 3 nodes}
	\label{figura:cpu3-4}
\end{figure}

Al aumentar el número de salas a 2 y 4 (Ver figuras~\ref{figura:cpu3-2} y \ref{figura:cpu3-4}), nos encontramos con el mismo comportamiento que en el caso de 2 nodos: uso de CPU estable ante la carga de trabajo.

\subsection{Uso de CPU en 4 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/1roomcpu.png}
	\caption{1 room(s) - CPU - 4 nodes}
	\label{figura:cpu4-1}
\end{figure}

Aumentando el número de nodos a 4 (Ver figura~\ref{figura:cpu4-1}) vemos cómo Akka muestra un coportamiento irregular haciendo un uso mayor de CPU con un número reducido de usuarios, estabilizandose a medida que aumenta la carga.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/2roomcpu.png}
	\caption{2 room(s) - CPU - 4 nodes}
	\label{figura:cpu4-2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/4roomcpu.png}
	\caption{4 room(s) - CPU - 4 nodes}
	\label{figura:cpu4-4}
\end{figure}

Al aumentar en número de salas para 4 nodos a 2 y 4 (Ver figuras ~\ref{figura:cpu4-2} y \ref{figura:cpu4-4})se observa que la aplicación de SpringBoot se reduce en mayor medida que las demás, situándose cercana a Akka.

\subsection{Conclusión del estudio: Uso de CPU}

Apreciamos una coorelación de esta métrica con la latencia, con la salvedad de SpringBoot+Hazelcast, que se equipara prácticamente con Vert.x. Ambas aplicaciones suponen la mejor opción al ofrecer los mejores resultados para esta métrica. Parece que el uso de Hazelcast resulta ligero frente a otras opciones en cuanto al uso de CPU.

Podemos determinar, comparandola con su versión con Hazelcast, que SpringBoot+RabbitMQ, al hacer uso de un servicio externo (en la propia máquina) consume bastante más CPU para ejecutar ambas aplicaciones (RabbitMQ y el WebChat en SpringBoot).

Akka presenta un uso sensiblemente superior de CPU respecto a las aplicaciones que usan Hazelcast. Es posible que los actores de esta librería sean más pesados que los de Vert.x.

\subsection{Restrospectiva: Uso de CPU}

Para finalizar el estudio del uso de CPU, volvamos a echar un vistazo a los resultados del proyecto anterior. Cabe destacar que las pruebas del estudio anterior se realizaron en una máquina con 8 cores de procesamiento, por lo que el uso de la CPU puede superar el 100\% (hasta un 800\%)

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{img/old/1roomcpu.png}
	\caption{1 room(s) - CPU - 1 node}
	\label{figura:old_cpu}
\end{figure}

En esta ocasión (Ver figura~\ref{figura:old_cpu}), se corresponde en gran medida a las nuevas métricas que hemos recogido, donde Spring y Vert.x hacen un uso de CPU similar mientras que Akka hace un uso bastante superior. Por lo tanto, la mayor diferencia la notariamos al hacer uso de RabbitMQ.

\section{Uso de memoria}

Al igual que el uso de la CPU, esta métrica se obtuvo mediante SSH, en esta ocasión haciendo uso del comando \textit{free} de linux. Corresponde a la cantidad (en MBytes) media de memoria utilizada por los nodos del clúster.

\pagebreak

\subsection{Uso de memoria en 2 nodos}

\begin{figure}[h!]
	\centering
		\includegraphics[scale=0.6]{img/labels3.png}
		\includegraphics[scale=0.55]{img/2nodes/1roomram.png}
	\caption{1 room(s) - Memory - 2 nodes}
	\label{figura:mem2-1}
\end{figure}

En la figura~\ref{figura:mem2-1} observamos cómo la aplicación que de nuevo hace un uso mayor del recurso es SpringBoot+RabbitMQ, mientras que las tecnologías basadas en actores necesitan la mitad de memoria para funcionar. Vemos una notable diferencia entre la aplicación de SpringBoot+Hazelcast con la de Vert.x.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/2nodes/2roomram.png}
	\caption{2 room(s) - Memory - 2 nodes}
	\label{figura:mem2-2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/2nodes/4roomram.png}
	\caption{4 room(s) - Memory - 2 nodes}
	\label{figura:mem2-4}
\end{figure}

\pagebreak

Apreciamos estabilidad a la hora de aumentar el número de salas de chat(Ver figuras~\ref{figura:mem2-2} y \ref{figura:mem2-4}), sin diferencias reseñables frente a lo anteriormente comentado.

\subsection{Uso de memoria en 3 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/1roomram.png}
	\caption{1 room(s) - Memory - 3 nodes}
	\label{figura:mem3-1}
\end{figure}

Aumentar el número de nodos (Ver figura~\ref{figura:mem3-1}), reduce sensiblemente la memoria utilizada, especialmente en SpringBoot+RabbitMQ, que se asemeja en el uso de este recurso a su versión con Hazelcast.

\pagebreak

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/2roomram.png}
	\caption{2 room(s) - Memory - 3 nodes}
	\label{figura:mem3-2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/3nodes/4roomram.png}
	\caption{4 room(s) - Memory - 3 nodes}
	\label{figura:mem3-4}
\end{figure}


Al aumentar el número de salas (Ver figuras~\ref{figura:mem3-2} y \ref{figura:mem3-4}), observamos la misma estabilidad que con dos nodos, volviendose aún mas similar el uso de este recurso en las aplicaciones de SpringBoot.

\subsection{Uso de memoria en 4 nodos}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/1roomram.png}
	\caption{1 room(s) - Memory - 4 nodes}
	\label{figura:mem4-1}
\end{figure}

En la figura ~\ref{figura:mem4-1} que las aplicaciones hacen un uso de memoria muy parecido al caso con 3 nodos.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/2roomram.png}
	\caption{2 room(s) - Memory - 4 nodes}
	\label{figura:mem4-2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.55]{img/4nodes/4roomram.png}
	\caption{4 room(s) - Memory - 4 nodes}
	\label{figura:mem4-4}
\end{figure}

Al igual que antes, el uso de memoria se estabiliza para todas las aplicaciones (Ver figuras~\ref{figura:mem4-2} y \ref{figura:mem4-4}), pero en este caso aumenta para la aplicación de SpringBoot+Hazelcast, situándola por encima de su versión con RabbitMQ.

\subsection{Conclusión del estudio: Uso de memoria}

Podemos afirmar que el uso de Hazelcast en este caso no es tan determinante, si no el cliente web. Esto puede observarse en la diferencia entre Vert.x y SpringBoot+Hazelcast, dónde la aplicación de SpringBoot hace un uso muy superior de este recurso, al igual que su versión con RabbitMQ.

Akka se mantiene en un uso de memoria similar a Vert.x, pero ligeramente superior en todos los caso, por lo que podemos afirmar que Vert.x es la mejor opción atendiendo a esta métrica.

\subsection{Restrospectiva: Uso de memoria}

Para finalizar el estudio del uso de memoria, echemos de nuevo un vistazo a los resultados del proyecto anterior. Cabe destacar que las pruebas del estudio anterior se realizaron en una máquina con 6 GBytes de memoria RAM, frente a 1 GByte que posee cada uno de los nodos de cualquier aplicación. En este caso, la memoria está en KBytes.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{img/old/1roomram.png}
	\caption{1 room(s) - Memory - 1 node}
	\label{figura:old_memory}
\end{figure}

Contrario a lo que podriamos observar en el uso de CPU, en el estudio anterior (Ver figura~\ref{figura:old_memory}) Vert.x mostraba un uso de memoria muy alto en cuanto el flujo de mensajes comenzaba a escalar demasiado (a partir de unos 450.000 mensajes). Podemos ver cómo Vert.x, al igual que en la comparativa actual, comienza siendo la que hace un uso menor de este recurso.

Este aumento repentino puede ser debido a una mala gestión de la memoria, concretamente a la eliminación de los \textit{handlers} que en la nueva versión si se solucionó. No se ha podido comprobar si al aumentar la carga de trabajo progresivamente (hasta, por ejemplo, los 1.8 millones de mensajes del estudio anterior) debido a las limitaciones de las máquinas disponibles.

Por otro lado, Akka y SpringBoot muestran tendencias similares al nuevo estudio, evidenciando que en este caso, al igual que al medir el uso de CPU, el uso de un servio externo como RabbitMQ aumenta considerablemente la memoria utilizada por la máquina que actúa cómo nodo de nuestro clúster.

\section{Desarrollo}

A la hora de desarrollar, también debemos plantearnos el tiempo y/o dificultad que nos puede entrañar, en este caso, crear un sistema de mensajería.

Tanto las aplicaciones de Akka y Vert.x disponen de amplias librerías que conllevan una curva de aprendiza inicial bastante mayor que el resto de tecnologías mostradas, introduciendo el modelo de actores de cara a resolver problemas de concurrencia. En el caso de Akka, además, se le añade la dificultad de incrustar nuestra aplicación en el framework Play para obtener un servidor WebSocket. Esta dificultad se ve recompensada con una sistema de comunicación entre nodos bastante sencilla una vez hemos construido una aplicación monolítica.

Por otro lado, las aplicaciones de SpringBoot son mucho más sencillas y rápidas de construir gracias a su inversión de control, aunque deja en manos del usuario solventar posibles problemas de concurrencia. Sin embargo, SpringBoot no proporciona ningún sistema de comunicación entre los distintos nodos, teniendo que hacer uso de librerias o servicios externos que degradan sus prestaciones en comparación a Akka y Vert.x, que integran todas sus funcionalidades en un mismo toolkit.

\pagebreak

\section{Conclusiones generales de la comparativa}

Para obtener una visión global de la comparativa, haremos uso un gráfico de dispersión (Ver figura~\ref{figura:dispersion}) para el caso más representativo por su alta carga de trabajo, 50 usuarios en una sola sala de chat, con un total de 250.000 de mensajes enviados y recibidos. La latencia queda reflejada por el tamaño de los puntos.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.6]{img/labels3.png}
	\includegraphics[scale=0.7]{img/bubblechart.png}
	\caption{4 room(s) - Memory - 3 nodes}
	\label{figura:dispersion}
\end{figure}

Los resultados del experimento quedan resumidos en la siguiente tabla.

\begin{center}
	\begin{tabular}{ | l | l | l | l | l |}
		\hline
		\textbf{Tecnología} & \textbf{Latencia} & \textbf{Uso de CPU} & \textbf{Uso de Memoria} & \textbf{Dificultad de desarrollo} \\ 
		\hline Akka & Baja & Medio & Bajo & Medio \\ 
		\hline Vert.x & Baja & Bajo & Bajo & Bajo \\ 
		\hline RabbitMQ & Alta & Alto & Alto & Medio \\ 
		\hline Hazelcast & Medio & Bajo & Medio & Bajo \\ \hline
	\end{tabular}
\end{center}

Tras estudiar las distintas métricas, podemos afirmar que si buscamos una aplicación basada en Websockets distribuida, fiable ante grandes cargas de trabajo y que no haga un uso excesivo de los recursos de las máquinas en las que se ejecuta, la tecnología óptima sería Vert.x.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. Conclusiones del proyecto y trabajos futuros %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones del proyecto y trabajos futuros}
\label{sec:conclusiones} 

Este proyecto ha sido un desafío y una fuente de aprendizaje sobre los sistemas distribuidos que me ha permitido enfrentarme a los problemas que podré encontrarme en un futuro al desarrollar este tipo de sistemas.

Quedan satisfechos los objetivos de este proyecto cómo continuación del proyecto anterior, que estudiaba la escalabilidad vertical de las tecnologías.

La posibilidad de ampliar este proyecto ha estado presente durante todo el desarrollo, facilitando en gran medida la inclusión de nuevas aplicaciones mediante un diseño flexible , una documentación detallada y un cliente de pruebas fácil de usar.

Entre las posibles ampliaciones/continuaciones del proyecto, destacaría:

\begin{itemize}
	\item La inclusión de nuevas tecnologías, no necesariamente basadas en Java, si no en otros lenguajes que proponen modelos de concurrencia interesantes cómo Erlang o Go.
	\item El desarrollo para cada tecnología de una distribución de carga propio (en lugar del \textit{round-robin} proporcionado por HAProxy) de forma que, por ejemplo, se situén usuarios con la misma sala en un mismo nodo.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\chapter{Despliegue de instancias en AWS}
\label{appendix1}

Para desplegar las instancias necesarias que usaremos indistintamente para cualquier tecnología necesitaremos cumplir los siguientes requisitos:

\begin{itemize}  
	\item Disponer de una cuenta en AWS (se recomienda que tenga en vigencia el año de capa gratuita para evitar costes)
	\item Tener instalada la interfaz de línea de comandos de AWS (aws-shell)
\end{itemize}

Una vez cumplimos los requisitos, será necesario crear un grupo de seguridad para nuestras instancias al que llamaremos \textit{Cluster}.

A continuación se muestra cómo crear un \textit{SecurityGroup} mediante aws-shell, dónde \textit{security-group-id} será el id devuelto por el primer comando.

\begin{lstlisting}
	aws ec2 create-security-group \
		--group-name Cluster \
		--description "My security group"
		
	aws ec2 authorize-security-group-ingress  \
		--group-id security-group-id \
		--protocol -1 --cidr 0.0.0.0/0
	
	aws ec2 authorize-security-group-ingress \
		--group-id security-group-id \
		--protocol tcp \
		--port 22 \
		--cidr 0.0.0.0/0
\end{lstlisting}

Estos comandos nos generarán un \textit{SecurityGroup} con unas reglas de entrada poco restrictivas pero muy flexibles de forma que no tengamos problemas para ninguna tecnlología. También permite que el desarrollador pueda conectarse mediante SSH. Puede especificarse una IP concreta para aumentar la seguridad.

Una vez creado el \textit{SecurityGroup}, lo utilizaremos para lanzar nuestras instancias. Para este experimento se han hecho uso de instancias t2.micro con la AMI correspondiente a una máquina Ubuntu Server 16.04 LTS, de forma que nos mantenemos en la capa gratuita. Para lanzar las instancias, haremos uso de nuevo del cliente por terminal ejecutando el siguiente script:

\begin{lstlisting}
	aws ec2 run-instances \
		--image-id ami-58d7e821 \
		--count N \
		--instance-type t2.micro \
		--key-name MyPem \
		--security-group-ids security-group-id \
		--subnet-id subnet-dd426694
\end{lstlisting}


\begin{itemize}  
	\item \textit{N} es el número de instancias a crear
	\item \textit{MyPem} es el par de claves de seguridad para poder conectarnos a la instancia mediante SSH. Si no disponemos de un par, podemos crearlas desde la consola web\footnote{\url{https://docs.aws.amazon.com/es_es/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair}}.
	\item \textit{security-group-id} es el id del \textit{SecurityGroup} creado en el paso anterior.
	\item La subnet \textit{subnet-dd426694} corresponde a la subnet por defecto de la zona eu-west-1a.
\end{itemize}

Una vez las instancias esten lanzadas y disponibles, podremos desplegar cualquiera de nuestras aplicaciones.

\end{document}
