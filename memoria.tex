\documentclass[a4paper, 12pt, oneside]{book}
\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel} 
\usepackage{url}
\usepackage{graphicx}
\usepackage{float} 
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{setspace}

\newcommand{\subsubsubsection}[1]{\paragraph{#1}\mbox{}\\}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\usepackage{listings}
\usepackage{color}
\usepackage{tcolorbox}
\tcbuselibrary{listingsutf8}

\title{Community Detection Algorithm}
\author{Michel Maes Bermejo}

\renewcommand{\baselinestretch}{1.5}

\begin{document}

\renewcommand{\refname}{Bibliografía} 
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA
\cleardoublepage
\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
\includegraphics[scale=0.6]{img/logos/urjc-logo.jpg} &
\end{tabular}

\vspace{1cm}

\Large
MASTER EN DATA SCIENCE

\vspace{0.4cm}

\large
Curso Académico 2018/2019

\vspace{0.8cm}

Trabajo Fin de Master

\vspace{2cm}

\LARGE
Divider Greedy algorithm for performing community detection in social networks

\vspace{2cm}

\large
Autor : Michel Maes Bermejo \\
Tutor : Jesús Sánchez-Oro Calvo

\end{center}
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%
%%%% Resumen
%%%%%%%%%%%%%%%%%%%%

\chapter*{Resumen}
\pagenumbering{gobble}

\markboth{RESUMEN}{RESUMEN} % encabezado

En este proyecto abordaremos la creación de un algoritmo capaz de detectar comunidades en redes sociales, un problema en el que los algoritmos tradicionales no ofrecen soluciones rápidas. Para ello usaremos un enfoque metaheurístico basado en la división de comunidades e intentaremos mejorar sus prestaciones a lo largo de varias iteraciones. (PENDIENTE DE TERMINAR TRAS FINALIZAR LA MEMORIA)

%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%

%%%% Índice de contenidos
\tableofcontents 
%%%% Índice de figuras
\cleardoublepage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%       1.INTRODUCCIÓN Y MOTIVACIÓN           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducción y motivación}
\label{sec:intro} 
\pagenumbering{arabic} 

Desde su nacimiento, Internet ha logrado conectar a las personas de forma sencilla. El ejemplo más claro son las redes sociales, que han crecido de forma contundente los últimos años. La rápidez con la que se transmite la información ha provocado que muchas personas las utilicen como medio de información de referencia frente a los tradicionales. Esto ha desencadenado un creciente interés de diferentes marcas e incluso de otros medios de aprovechar este fenómeno para su beneficio, aprovechando la estructura de red (o grafo) en la que se basa.

Desde el punto de vista de un científico de datos, resulta interesante estudiar la estructura que formas estas redes, que constituyen un ejemplo perfecto  de un grafo. Una de las áreas más interesantes que utiliza como base este tipo de redes es la detección de comunidades, que cuenta con multitud de aplicaciones.

Actualmente existen multitud de algoritmos que abordan el problema de la detección de comunidades. Los más tradicionales y exactos no son viables para abordar los grandes volumenes de datos que generan las redes sociales, por lo que se ha optado por soluciones heuristicas, no tan exactas, pero mucho más rápidas.

La motivación de este proyecto nace de la idea de crear una solución heurística diferente a las preexistentes (normalmente basadas en algun algun algoritmo destructivo), optando por un enfoque destructivo.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%             2. Objetivos                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Objetivos}
\label{sec:objetivos} 

El objetivo principal de este proyecto será la creación de un algoritmo de detección de comunidades. Para ello utilizaremos un enfoque destructivo (comenzar con todos los nodos del grafo en la misma comunidad e ir haciendo particiones) contrario a un enfoque más utilizado, constructivo (comenzar con cada nodo en su propia comunidad e ir agrupandolos). Durante la construcción, usaremos la modularidad como métrica para evaluar nuestra solución. Realizaremos una serie de iteraciones en las cuales iremos mejorando el algoritmo con el fin de obtener la mejor versión del mismo.

Finalmente, compararemos nuestro algoritmo con otros preexistentes para valorar si es efectivo el enfoque elegido. En esta fase usaremos otras métricas sobre las particiones obtenidas como la conductancia o covertura.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3. Tecnologías, Herramientas y Metodologías %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Tecnologías, Herramientas y Metodologías}
\label{sec:tecnologias} 

\section{Tecnologías}

\subsection{Java}
\label{subsec:java}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.04]{img/logos/java-logo.png}
	\caption{Logo Java}
	\label{figura:java}
\end{figure}

Java (Figura~\ref{figura:java}) es un lenguaje de programación de propósito general, concurrente y orientado a objetos. Su sintaxis deriva en gran medida de C y C++. Uno de los principales atractivos de Java es su máquina virtual (JVM) que nos permite ejecutar nuestro código Java en cualquier dispositivo, independientemente de la arquitectura.

\cleardoublepage
\section{Herramientas}

\subsection{Control de versiones: Git}
\label{subsec:git}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.08]{img/logos/git-logo.png}
	\caption{Logo Git}
	\label{figura:git}
\end{figure}


Git\footnote{\url{https://git-scm.com/}} (Figura~\ref{figura:git}) es un software de control de versiones diseñado por Linus Torvalds, pensando en la eficiencia y la confiabilidad del mantenimiento de versiones de aplicaciones cuando éstas tienen un gran número de archivos de código fuente.

\subsection{Entorno de desarrollo: IntelliJ}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.3]{img/logos/intellij-logo.png}
	\caption{Logo IntelliJ}
	\label{figura:intellij}
\end{figure}


IntelliJ\footnote{\url{https://www.jetbrains.com/idea/}} (Figura~\ref{figura:intellij}) es un IDE para Java desarollado por JetBrains ideado para mejorar la productividad del programador. 

\section{Metodologías}

Dado que pretendemos obtener la mejor versión de nuestro algoritmo, el desarrollo seguirá una metodología iterativa-incremental\footnote{\url{https://proyectosagiles.org/desarrollo-iterativo-incremental/}}, dónde en cada iteración se propondrán y evaluarán diferentes mejoras sobre el algoritmo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 		 4. Descripción informática           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Descripción informática}
\label{sec:descinformatica} 

En este apartado se abordará la construcción del proyecto. Este proyecto consta de una colección de algoritmos de detección de comunidades, que parte desde un algoritmo de detección aleatoria, pasando por la evolución de un algoritmo destructivo hasta obtener la mejor versión del mismo aplicando una búsqueda local.

\section{Requisitos}

\subsection{Requisitos funcionales}

Los requisitos funcionales de la aplicación son simples dado que se trata de un algoritmo:

\begin{itemize}
	\item Debe poder leer un fichero de entrada (correspondiente al grafo a tratar).
	\item Dado esa entrada y un algoritmo, debe devolver los clústers resultantes al realizar la detección de comunidades.  
\end{itemize}

\subsection{Requisitos no funcionales}

Los requisitos no funcionales de la aplicación se reducen a la calidad de la solución ofrecida y al tiempo de ejecución:

\begin{itemize}
	\item Maximizar la modularidad.
	\item Ofrecer el menor tiempo de cálculo posible\footnote{Existen algoritmos que ofrecen soluciones óptimas a este problema, pero no son aplicables a grafos grandes dado que requieren demasiado tiempo de computo.}. 
\end{itemize}

\begin{tcolorbox}[fonttitle=\bfseries,title=Modularidad,label=alg1]
	Las soluciones de los algoritmos de detección de comunidades se construyen máximizando su valor de modularidad, una medida utilizada para medir la fuerza de division de un grafo en clústers. Esta métrica se define cómo la fracción de enlaces que caen dentro de los clústers dados menos el valor esperado que dicha fracción hubiese recibido si los enlaces se hubiesen distribuido al azar. De forma matemática:
	
	\begin{equation*}
	Md(S,G) = \sum_{j=1}^{max(S)} (e_{jj} - a^{2}_{j})
	\end{equation*}
	
	dónde $S$ es la solución y $G$ el grafo, siendo $e_{jj}$ la fracción de enlaces con ambos vértices finales en el mismo grupo:
	
	\begin{equation*}
	e_{jj} = \frac{|\{(v,u) \epsilon E : S_{v} = S_{u} = j\}|}{|E|}
	\end{equation*}
	
	y $a_{j}$ la fracción de enlaces con al menos un extremo en la misma comunidad:
	
	\begin{equation*}
	a_{j} = \frac{|\{(v,u) \epsilon E : S_{v} = j\}|}{|E|}
	\end{equation*}
	siendo en ambos caso $E$ el conjunto de las aristas de $G$.
	
	La modularidad toma valor en el intervalo [-.5,1)
\end{tcolorbox}

\section{Diseño e implementación}

A continuación, se detallará la construcción incremental del algoritmo, explicando cada versión creada. Las premisas para todos los algoritmos son las siguientes:

\begin{itemize}
	\item Se comienza con todos en la misma comunidad.
	\item Se asume un grafo conexo
\end{itemize}

\begin{tcolorbox}[fonttitle=\bfseries,title=Grafo conexo,label=alg1]
Un grafo conexo $\overline{G}$ es todo grafo $G$ dónde para cada par de vertices $(x,y)$ existe un camino $P$.

\end{tcolorbox}

Para estimar cómo de buena es cada versión del algoritmo usaremos un grafo de ejemplo representativo que llamaremos \textit{Instancia de Prueba} (214 nodos y 1954 aristas).

\subsection{ConstRandom: Algoritmo aleatorio}

En esta primera aproximación (Algoritmo \ref{alg1}) que nos sirve como punto de partida y para posterior comparación, generamos los clústers de manera aleatoria; se crea un número aleatorio de clústers y se distribuyen los nodos de forma aleatorio en ellos.

\begin{algorithm}
	\caption{ConsRandom algorithm}\label{alg1}
	\begin{algorithmic}[1]
		\Procedure{ConstRandom}{$G$}\Comment{The graph 'G'}
			\State $S \gets EmptySolution(G)$
			\State $numClusters \gets Random(N(g))$\Comment{N returns nº of graph nodes}
			
			\For{$i=0$ to $numClusters$}
				\State $createEmptyCluster(S)$
			\EndFor
			
			\For{$i=0$ to $N(S)$}
				\State $rnd \gets Random(numClusters)$
				\State $AssignToCluster(S, i, rnd)$ \Comment{Assign node $i$ to cluster $rnd$ in solution $S$}
			\EndFor
			\State \textbf{return} $S$
		\EndProcedure
	\end{algorithmic}
	\textbf{Modularidad para Instancia de Prueba: -0.007}	
\end{algorithm}



\subsection{ConstDivider: Primer aproximación}

Este algoritmo supone el primer intento de aplicar un enfoque divisor a la detección de comunidades. Los pasos del algoritmo a seguir son los siguiente (Ver junto al Algoritmo~\ref{alg2}):
\begin{enumerate}
	\item Comenzamos con una sola comunidad que contiene todos los nodos.
	\item Se busca el nodo peor conectado (menor número de aristas) ó el primero que encuentre una arista.
	\item Se crea un nuevo clúster con ese nodo y se añaden los adyacentes en la medida en la que aumente la modularidad. Se descartan los adyacentes de los nodos los cuales no han mejorado la modularidad. De esta manera, se crearán dos clústers (A y B).
	\item Repetimos los pasos 1-3 con el clúster B hasta que no se generen nuevos clusters.
\end{enumerate}

\begin{algorithm}
	\caption{ConstDivider algorithm}\label{alg2}
	\begin{algorithmic}[1]
		\Procedure{ConstDivider}{$G$}\Comment{The graph 'G'}
			\State $S \gets EmptySolution(G)$
			\State $S' \gets S$
			
			\State $c \gets 0$\Comment{Current cluster index}
			\While{$c < Size(S')$}
				\State $K \gets EmptySet()$\Comment{Checked Nodes}
				\State $S'' \gets S'$
				\State $createEmptyCluster(S'')$	
				\State $wcn <- GetWorstConnectedNode(S'')$
				\State $Move(wcn, c+1, S'')$\Comment{Move node $wcn$ to cluster $c+1$ in solution $S''$}  
				\State $A \gets Adyacents(G, wcn)$
				\While{$Size(A) > 0$}
					\State $i <- Poll(A)$
					\State $K <- Append(K, i)$
					\State $Move(i, c+1, S'')$
					\If{$Md(S'', G) > Md(S', G)$} 
						\State $S' <- S''$
					\EndIf
					\For{$j \epsilon Adyacents(i)$}
						\If{$j \notin K \And j \notin Cluster(S'', c)$}
						\State $A <- Remove(A, node)$
						\State $K <- Append(K, node)$
						\EndIf
					\EndFor
				\EndWhile
				\If{$Md(S', G) > Md(S, G)$} 
					\State $ S \gets S'$
				\Else 
					\State  $c \gets c + 1$
				\EndIf
			\EndWhile
			\State \textbf{return} $S$
		\EndProcedure
	\end{algorithmic}
	\textbf{Modularidad para Instancia de Prueba: 0.096}
\end{algorithm}

\subsection{ConstDividerGreedy: Segunda aproximación}

Podemos observar como la mejora en cuanto a modularidad no es destacable (recordemos que la modularidad toma un valor entre -0.5 y 1.0). Es necesario utilizar otro enfoque. El problema de este algortimo es que una mala elección del primer nodo puede provocar que no se formen correctamente las comunidades. Aleatorizar este la elección de este primer nodo nos abre la puerta a realizar múltiples iteraciones comenzando desde distintos nodos. Los pasos a seguir en este algoritmo serían (Ver junto al Algoritmo~\ref{alg3}):
\begin{itemize}
	\item Se elige el primer nodo de forma aleatoria, añadiendo, como antes, los nodos adyacentes si aumenta la modularidad.
	\item Se crea una lista de candidatos, que contiene a todos los vertices ordenados por el número de aristas que vayan a otro clúster de mayor a menor.
	\item A partir de una funcion voraz (Ver Funcion \ref{func1}), obtenemos un umbral $mu$, que restringe la lista a los vértices con un número de vertices mayor que $mu$.
	\item El siguiente vértice se selecciona al azar de esta lista restringida.
	\item Se repite este proceso hasta que no mejora la modularidad.
\end{itemize}

\begin{tcolorbox}[fonttitle=\bfseries,title=Función Voraz,label=func1]
	Dado $g_{max}$ y $g_{min}$ cómo los valores mayor y menos de nuestra función voraz (el número de aristas) y $\alpha$ un parámetro en el rango [0,1] (que indicará cómo de voraz es nuestro algoritmo, siendo 1 completamente aleatorio y 0 totalmente voraz), el umbral $mu$ se calcula siguiendo la siguiente función:
	\begin{equation*}
		mu = g_{max} - \alpha * (g_{max} - g_{min})
	\end{equation*}
\end{tcolorbox}

Para probar el algoritmo se han utilizado los siguientes valores de $\alpha$: 0.0, 0.25, 0.5, 0.75, 1.

\begin{algorithm}
	\caption{ConstDividerGreedy algorithm}\label{alg3}
	\begin{algorithmic}[1]
		\Procedure{ConstDividerGreedy}{$G, \alpha$}\Comment{The graph 'G' and param '$\alpha$'}
		\State $S \gets EmptySolution(G)$
		\State $S' \gets S$
		\State $c \gets 0$\Comment{Current cluster index}
		\State $b \gets GetRandom(S', c)$\Comment{Base node}
		\State $refactorIters \gets 10$
		
		\While{$c < Size(S') \And b \neq -1 \And refactorIters > 0$}
			\State $K \gets EmptySet()$\Comment{Checked Nodes}
			\State $S'' \gets S'$
			\State $createEmptyCluster(S'')$	
			
			\State $candidates \gets RestrictedList(G,c, \alpha)$
			\If{$Empty(candidates)$}
				\State{$b \gets GetRandom(candidates)$}	
			\Else
				\State{$b \gets GetRandom(S', c)$}
			\EndIf
			
			\If{$b = -1$}
				\State $c \gets 0$
				\State $refactorIters \gets refactorIters - 1$
				\State \textbf{continue}
			\EndIf
			
			\State $Move(b, c+1, S'')$\Comment{Move node $b$ to cluster $c+1$ in solution $S''$}  
			\State $A \gets Adyacents(G, wcn)$
			\While{$Size(A) > 0$}
				\State $i <- Poll(A)$
				\State $K <- Append(K, i)$
				\State $Move(i, c+1, S'')$
				\If{$Md(S'', G) > Md(S', G)$} 
					\State $S' <- S''$
				\EndIf
				\For{$j \epsilon Adyacents(i)$}
					\If{$j \notin K \And j \notin Cluster(S'', c)$}
						\State $A <- Remove(A, node)$
						\State $K <- Append(K, node)$
					\EndIf
				\EndFor
			\EndWhile
			
			\If{$Md(S', G) > Md(S, G)$} 
				\State $ S \gets S'$
			\EndIf
			
			\State  $c \gets c + 1$
			
			
		\EndWhile
		\State \textbf{return} $S$
		\EndProcedure
	\end{algorithmic}
	\textbf{Modularidad para Instancia de Prueba (1000 iteraciones y $\alpha$ = 0.0): 0.251 }
\end{algorithm}

\subsection{ConstDividerGreedy + Local Search: Última versión}

La modularidad obtenida trás aplicar un enfoque voraz mejora de forma considerable. A pesar de ello, intentaremos aumentarla aún más partiendo de un heurístico no contemplado hasta ahora, la búsqueda local. Esta búsqueda local utilizará la solución de cada iteración del algortimo anterior (ConstDividerGreedy) e intentará mejorarla cambiando algunos nodos de clúster. La búsqueda local implementada se detalla a continuación (Ver junto al Algoritmo~\ref{alg4}):
\begin{itemize}
	\item Para cada clúster, se crea una lista de candidatos a moverse. Esta lista de candidatos estará ordenada por el \% de aristas que caen fuera del clúster.
	\item Cada nodo de esta lista de candidatos se intenta mover a otro clúster (incluido a un nuevo clúster). Si la modularidad mejora, se actualiza la solución, pero se siguen explorando otros movimientos.
\end{itemize}

Para probar el algoritmo se han utilizado los siguientes valores de $\alpha$: 0.0, 0.25, 0.5, 0.75, 1.

\begin{algorithm}
	\caption{LocalSearch algorithm}\label{alg4}
	\begin{algorithmic}[1]
		\Procedure{LocalSearch}{$S, G$}\Comment{The Solution 'S' and Graph 'G'}
		\State $i \gets 0$\Comment{Current cluster index}
		\While{$i < Size(S)$}
			\State $CL \gets CandidateList(S, i)$
			\While{$Size(CL) > 0$}
				\State $c \gets Poll(CL)$\Comment{Current candidate}
				\State $S' \gets S$
				\State $createEmptyCluster(S')$
				\State $j \gets 0$\Comment{Target cluster}
				\While{$j < Size(S)$}
					\If{$j = i$} 
						\State $j \gets j + 1$
						\State \textbf{continue}
					\EndIf
					\State $Move(c, j, S')$\Comment{Move node $c$ to cluster $j$ in solution $S'$}
					\If{$Md(S', G) > Md(S, G)$} 
						\State $S <- S'$
					\EndIf
					\State $Move(c, i, S')$\Comment{Return node $c$ to cluster $i$ in solution $S'$}
				 	\State $j \gets j + 1$
				\EndWhile
			\EndWhile
			\State $i \gets i + 1$
		\EndWhile
		\State \textbf{return} $S$
		\EndProcedure
	\end{algorithmic}
	\textbf{Modularidad para Instancia de Prueba (1000 iteraciones y $\alpha$ = 0.25): 0.3295 }
\end{algorithm}

Observamos que para $\alpha = 0.25$ obtenemos un resultado notablemente mejor que con el anterior algoritmo y consideramos \textit{ConstDividerGreedy + Local Search} la última versión de nuestro algoritmo.

\subsection{Paralelización}

Una vez obtenida una modularidad aceptable, terminaremos el desarrollo procurando optimizar el uso de los recursos de la máquina dónde se ejecute el algoritmo. Se hará uso de la libreria estándar de java para el manejo de hilos, $java.util.concurrent$, concretamente de los Ejecutores ($Executors$), que nos permiten gestionar de forma sencilla y óptima la casuística de la programación concurrente. Las tareas a paralelizar de nuestro programa serán las iteraciones del algoritmo.

Para demostrar la eficacia de usar paralelización en este algoritmo, usaremos de ejemplo la ejecución del algoritmo más lento: $ConstDividerGreedy + Local Search$. La siguiente prueba se ha realizado en una máquina Ubuntu 16.04 con 16GB de RAM y 4 procesadores (sin \textit{hyper-threading}).

Tiempos de ejecucción (en milisegundos) para 1000 iteraciones:
\begin{itemize}
	\item Secuencial: 			446.187 ms
	\item Paralelo (4 hilos):   132.753 ms
\end{itemize}

Podemos observar que se reduce de forma considerable (hasta un 70\%) el tiempo de ejecución, atendiendo a nuestro requisito no funcional de ofrecer el menor tiempo de ejecución posible.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 		   5. Estudio comparativo             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Estudio comparativo}
\label{sec:estudio} 

El estudio comparativo que se llevará a cabo a continuación constará de dos secciones:

\begin{itemize}
	\item La primera usará un conjunto de grafos de \textit{'entrenamiento'} que servirá para comparar los actuales algoritmos junto a los posibles valores de sus parámetros en términos de modularidad.
	\item La segunda usará un conjunto de grafos de \textit{test} (distintos al primero) que servirán para comparar la mejor versión de nuestro algoritmo con otras soluciones pre-existentes en términos de conductancia y cobertura.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. Conclusiones del proyecto y trabajos futuros %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones del proyecto y trabajos futuros}
\label{sec:conclusions} 

Prueba cita~\cite{jya1}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

\bibliographystyle{abbrv}
\bibliography{memoria} 

\end{document}


